[
  {
    "objectID": "lectures/lecture_6.html#overview",
    "href": "lectures/lecture_6.html#overview",
    "title": "Replication Workshop",
    "section": "Overview",
    "text": "Overview"
  },
  {
    "objectID": "lectures/lecture_6.html#overview-1",
    "href": "lectures/lecture_6.html#overview-1",
    "title": "Replication Workshop",
    "section": "Overview",
    "text": "Overview\nRecap of previous lectures"
  },
  {
    "objectID": "lectures/lecture_6.html#overview-2",
    "href": "lectures/lecture_6.html#overview-2",
    "title": "Replication Workshop",
    "section": "Overview",
    "text": "Overview\nQuarto showcase\n\nWalktrough of a quarto document that includes the Dielgate analyses\nShow how to handle references\nPut on GitHub"
  },
  {
    "objectID": "lectures/lecture_6.html#overview-3",
    "href": "lectures/lecture_6.html#overview-3",
    "title": "Replication Workshop",
    "section": "Overview",
    "text": "Overview\nToday‚Äôs learning objectives"
  },
  {
    "objectID": "lectures/lecture_6.html#overview-4",
    "href": "lectures/lecture_6.html#overview-4",
    "title": "Replication Workshop",
    "section": "Overview",
    "text": "Overview\nWhat‚Äôs on the menu today?"
  },
  {
    "objectID": "lectures/lecture_6.html#ingredients",
    "href": "lectures/lecture_6.html#ingredients",
    "title": "Replication Workshop",
    "section": "Ingredients",
    "text": "Ingredients"
  },
  {
    "objectID": "lectures/lecture_6.html#goals-what-do-we-want-to-replicate",
    "href": "lectures/lecture_6.html#goals-what-do-we-want-to-replicate",
    "title": "Replication Workshop",
    "section": "Goals: What do we want to replicate?",
    "text": "Goals: What do we want to replicate?"
  },
  {
    "objectID": "lectures/lecture_6.html#jupyter-notebook---walkthrough",
    "href": "lectures/lecture_6.html#jupyter-notebook---walkthrough",
    "title": "Replication Workshop",
    "section": "Jupyter Notebook - Walkthrough",
    "text": "Jupyter Notebook - Walkthrough"
  },
  {
    "objectID": "lectures/lecture_6.html#what-can-we-add-discussion",
    "href": "lectures/lecture_6.html#what-can-we-add-discussion",
    "title": "Replication Workshop",
    "section": "What can we add? Discussion",
    "text": "What can we add? Discussion"
  },
  {
    "objectID": "lectures/lecture_6.html#references",
    "href": "lectures/lecture_6.html#references",
    "title": "Replication Workshop",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "lectures/lecture_4.html#overview",
    "href": "lectures/lecture_4.html#overview",
    "title": "De Do Do Do, De Di i Di - Panel Data Methods",
    "section": "Overview",
    "text": "Overview"
  },
  {
    "objectID": "lectures/lecture_4.html#overview-1",
    "href": "lectures/lecture_4.html#overview-1",
    "title": "De Do Do Do, De Di i Di - Panel Data Methods",
    "section": "Overview",
    "text": "Overview\nToday‚Äôs learning objectives\n\nWhat are good and bad controls in regression analysis?\nUnderstand the Difference-in-Differences (DiD) framework for causal inference using panel data\nLearn how to implement DiD design, including fixed effects\nRecognize the importance of appropriate standard error adjustments in DiD analyses\nExplore advanced DiD topics such as staggered adoption and recent methodological developments"
  },
  {
    "objectID": "lectures/lecture_4.html#overview-2",
    "href": "lectures/lecture_4.html#overview-2",
    "title": "De Do Do Do, De Di i Di - Panel Data Methods",
    "section": "Overview",
    "text": "Overview\nRecap of previous lecture"
  },
  {
    "objectID": "lectures/lecture_4.html#overview-3",
    "href": "lectures/lecture_4.html#overview-3",
    "title": "De Do Do Do, De Di i Di - Panel Data Methods",
    "section": "Overview",
    "text": "Overview\nToday‚Äôs learning objectives\n\nWhat are good and bad controls in regression analysis?\nUnderstand the Difference-in-Differences (DiD) framework for causal inference using panel data\nLearn how to implement DiD design, including fixed effects\nRecognize the importance of appropriate standard error adjustments in DiD analyses\nExplore advanced DiD topics such as staggered adoption and recent methodological developments"
  },
  {
    "objectID": "lectures/lecture_4.html#what-to-do-if-random-assignment-is-not-possible-1",
    "href": "lectures/lecture_4.html#what-to-do-if-random-assignment-is-not-possible-1",
    "title": "De Do Do Do, De Di i Di - Panel Data Methods",
    "section": "What to do if random assignment is not possible?",
    "text": "What to do if random assignment is not possible?\nBuilding the OLS model\nOLS model building blocks\n\n\n\n\nI took this figure from Huntington-Klein (2022) chapter 13!"
  },
  {
    "objectID": "lectures/lecture_4.html#control-variables-in-regression-analysis-1",
    "href": "lectures/lecture_4.html#control-variables-in-regression-analysis-1",
    "title": "De Do Do Do, De Di i Di - Panel Data Methods",
    "section": "Control Variables in Regression Analysis",
    "text": "Control Variables in Regression Analysis\nGood vs.¬†Bad controls\n\n\nGood controls\n\nVariables that are correlated with the outcome but not with the treatment\nHelp reduce omitted variable bias\nImprove precision of estimates\n\n\nBad controls\n\nVariables that are affected by the treatment (mediators)\nVariables that are correlated with both treatment and outcome (colliders)\nCan introduce bias into estimates"
  },
  {
    "objectID": "lectures/lecture_4.html#control-variables-in-regression-analysis-2",
    "href": "lectures/lecture_4.html#control-variables-in-regression-analysis-2",
    "title": "De Do Do Do, De Di i Di - Panel Data Methods",
    "section": "Control Variables in Regression Analysis",
    "text": "Control Variables in Regression Analysis\nGood controls - Examples\n\n\nConfounder - ‚ÄúCommon cause‚Äù\n\n\n‚ÄúHidden common cause‚Äù\n\n\n\nDiLLMA example: controlling for study hours and attendance rate\n\n\n\nFor more details on causal diagrams check Huntington-Klein (2022) chapters 6-9 and bad controls Cinelli, Forney, and Pearl (2024)!"
  },
  {
    "objectID": "lectures/lecture_4.html#control-variables-in-regression-analysis-3",
    "href": "lectures/lecture_4.html#control-variables-in-regression-analysis-3",
    "title": "De Do Do Do, De Di i Di - Panel Data Methods",
    "section": "Control Variables in Regression Analysis",
    "text": "Control Variables in Regression Analysis\nBad controls - Examples\n\n\nMediator\n\n\nVariables that lie on the causal path between treatment and outcome\nControlling for mediator can block part of the treatment effect, leading to biased estimates\n\n\nCollider\n\n\nVariables that are influenced by both treatment and outcome\nControlling for collider can open a backdoor path, introducing spurious associations and bias"
  },
  {
    "objectID": "lectures/lecture_4.html#control-variables-in-regression-analysis-4",
    "href": "lectures/lecture_4.html#control-variables-in-regression-analysis-4",
    "title": "De Do Do Do, De Di i Di - Panel Data Methods",
    "section": "Control Variables in Regression Analysis",
    "text": "Control Variables in Regression Analysis\nBad controls - Example\n\n\nMediator\n\n\nVariables that lie on the causal path between treatment and outcome\nControlling for mediator can block part of the treatment effect, leading to biased estimates\n\n\nSimple Mediator Example\n\n\nBias arises from controlling fro a variable that lies on the causal path X ‚Üí C ‚Üí Y\nIf we include reported earnings as a control in a regression of market return on accounting choices, we remove part of the effect of accounting on returns.\n\n\n#TODO: Add more examples"
  },
  {
    "objectID": "lectures/lecture_4.html#difference-in-differences-did-1",
    "href": "lectures/lecture_4.html#difference-in-differences-did-1",
    "title": "De Do Do Do, De Di i Di - Panel Data Methods",
    "section": "Difference-in-Differences (DiD)",
    "text": "Difference-in-Differences (DiD)\nKey concepts\n\n\n\n\n\n\nWhat is Difference‚Äëin‚ÄëDifferences (DID)?\n\n\nDifference‚Äëin‚ÄëDifferences (DID) is a quasi‚Äëexperimental method that exploits within‚Äëgroup variation over time and cross‚Äëgroup variation to identify a causal effect when random assignment is infeasible."
  },
  {
    "objectID": "lectures/lecture_4.html#difference-in-differences-did-2",
    "href": "lectures/lecture_4.html#difference-in-differences-did-2",
    "title": "De Do Do Do, De Di i Di - Panel Data Methods",
    "section": "Difference-in-Differences (DiD)",
    "text": "Difference-in-Differences (DiD)\nWhy Differnces - Isn‚Äôt one difference enough?\n\n\nBefore vs After (time variation)\nWhat is it?\nCompare outcomes before and after treatment implementation, e.g.¬†pre- and post-policy change\nWhy not enough for causal inference?\nAll variation in Treatment is explained by Time!\n\nTreated vs Control (group variation)\nWhat is it?\nCompare outcomes between treated and control groups, e.g.¬†those affected by a policy change vs those not affected\nWhy not enough for causal inference?\nDifferences between Treated and Control groups may be driven by time-invariant confounders, e.g.¬†ability, demographics, location, etc.\n\nCombining both, allows to isolating the causal impact of the treatment a.k.a. average treatment effect on the treated (ATT)"
  },
  {
    "objectID": "lectures/lecture_4.html#difference-in-differences-did-3",
    "href": "lectures/lecture_4.html#difference-in-differences-did-3",
    "title": "De Do Do Do, De Di i Di - Panel Data Methods",
    "section": "Difference-in-Differences (DiD)",
    "text": "Difference-in-Differences (DiD)\nWhy Differnces - Isn‚Äôt one difference enough?\nA picture is worth a thousand words\n\n\n\n\n\n\n\nDiD only recovers the causal effect if the ‚Äúparallel trends assumption‚Äù holds!"
  },
  {
    "objectID": "lectures/lecture_4.html#difference-in-differences-did-4",
    "href": "lectures/lecture_4.html#difference-in-differences-did-4",
    "title": "De Do Do Do, De Di i Di - Panel Data Methods",
    "section": "Difference-in-Differences (DiD)",
    "text": "Difference-in-Differences (DiD)\nDiLLMa - Setting continued\n\nWe observe students‚Äô exam scores before and after LLMs were introduced 1\nSome courses allowed LLM use (treatment), others banned it (control)\nGoal: Estimate the causal effect of allowing LLM use on exam scores\n\nIn short\nCompare grade changes in allowed vs.¬†banned courses, before and after LLMs became available\n\nDiD isolates the treated group‚Äôs response, conditional on the assumption that the untreated group‚Äôs changes represent the non-treatment counterfactual for the treated group\n\nIt is worth noting that the underlying data is a panel dataset with multiple observations per student."
  },
  {
    "objectID": "lectures/lecture_4.html#difference-in-differences-did-5",
    "href": "lectures/lecture_4.html#difference-in-differences-did-5",
    "title": "De Do Do Do, De Di i Di - Panel Data Methods",
    "section": "Difference-in-Differences (DiD)",
    "text": "Difference-in-Differences (DiD)\nCanonical DiD model - The two-by-two design\nThe two-by-two set-up\n\n\n\n\n\n\n\n\n\n\n(1) After\n(2) Before\n(1) - (2)\n\n\n\n\n(a) Treatment\nY\\(_{treated,\\ after}\\)\nY\\(_{treated,\\ before}\\)\n\\(\\Delta_{treated}\\)\n\n\n(b) Control\nY\\(_{control,\\ after}\\)\nY\\(_{control,\\ before}\\)\n\\(\\Delta_{control}\\)\n\n\n(a) - (b)\n\\(\\Delta_{after}\\)\n\\(\\Delta_{before}\\)\nDiD\n\n\n\nA typical DiD regression looks like this\n\\[Y = \\beta_0 + \\beta_1 Treated + \\beta_2 After + \\beta_3 Treated \\times After + \\epsilon\\]\n\nThe difference-in-differences regression gives you the same estimate as if you took differences in the group averages\nIt takes also care of any unobserved constant differences between subjects and time trends!"
  },
  {
    "objectID": "lectures/lecture_4.html#difference-in-differences-did-6",
    "href": "lectures/lecture_4.html#difference-in-differences-did-6",
    "title": "De Do Do Do, De Di i Di - Panel Data Methods",
    "section": "Difference-in-Differences (DiD)",
    "text": "Difference-in-Differences (DiD)\nCanonical DiD model - The two-by-two design\nThe two-by-two set-up\n\n\n\n\n\n\n\n\n\n\n(1) After\n(2) Before\n(1) - (2)\n\n\n\n\n(a) Treatment\n\\(\\beta_0 + \\beta_1+\\beta_2+\\beta_3\\)\n\\(\\beta_0 + \\beta_1\\)\n\\(\\beta_2+\\beta_3\\)\n\n\n(b) Control\n\\(\\beta_0 + \\beta_2\\)\n\\(\\beta_0\\)\n\\(\\beta_2\\)\n\n\n(a) - (b)\n\\(\\beta_1+\\beta_3\\)\n\\(\\beta_1\\)\n\\(\\beta_3\\)\n\n\n\nA typical DiD regression looks like this\n\\[Y = \\beta_0 + \\beta_1 Treated + \\beta_2 After + \\beta_3 Treated \\times After + \\epsilon\\]\n\nThe difference-in-differences regression gives you the same estimate as if you took differences in the group averages\nIt takes also care of any unobserved constant differences between subjects and time trends!"
  },
  {
    "objectID": "lectures/lecture_4.html#difference-in-differences-did-7",
    "href": "lectures/lecture_4.html#difference-in-differences-did-7",
    "title": "De Do Do Do, De Di i Di - Panel Data Methods",
    "section": "Difference-in-Differences (DiD)",
    "text": "Difference-in-Differences (DiD)\nCanonical DiD model - The two-by-two design\nExample data summary\n\n\nSame variables as in previous lecture, but now panel data with multiple observations per student\nTreatment assigned at the course level (some instructors allow LLM use, others ban it)\nData contains two periods: pre-LLM (before) and post-LLM (after), each consisting of two exam scores per student\nThe unit of analysis is the student-time level\nThe key variables are:\n\ntreated: Indicator for whether the course allows LLM use (1 = yes, 0 = no)\nafter: Indicator for whether the observation is from the post-LLM period (1 = after, 0 = before)\nexam_score: The student‚Äôs exam score"
  },
  {
    "objectID": "lectures/lecture_4.html#difference-in-differences-did-8",
    "href": "lectures/lecture_4.html#difference-in-differences-did-8",
    "title": "De Do Do Do, De Di i Di - Panel Data Methods",
    "section": "Difference-in-Differences (DiD)",
    "text": "Difference-in-Differences (DiD)\nCanonical DiD model - The two-by-two design\n\n\nComparing means\n\n\n\n\n\n\nAfter\nBefore\nDifference\n\n\n\n\nTreated group\n6.57\n7.12\n-0.55\n\n\nControl group\n7.42\n7.22\n0.20\n\n\nDifference\n-0.85\n-0.10\n-0.75\n\n\n\n\n\n\nEstimation"
  },
  {
    "objectID": "lectures/lecture_4.html#difference-in-differences-did-.smaller",
    "href": "lectures/lecture_4.html#difference-in-differences-did-.smaller",
    "title": "De Do Do Do, De Di i Di - Panel Data Methods",
    "section": "Difference-in-Differences (DiD) .{smaller}",
    "text": "Difference-in-Differences (DiD) .{smaller}\n2-way fixed effects model\n\\[Y = \\alpha_i + \\alpha_t + \\beta_3 Treated \\times After + \\epsilon\\]\n\n\nWhat is absorbed by fixed effects?\n\n\\(\\beta_0\\) disappears - not meaningful in panel data with fixed effects\n\\(\\beta_1\\) disappears - time-invariant differences are absorbed by individual fixed effects\n\\(\\beta_2\\) disappears - time fixed effects capture common shocks over time\n\n\nWhy use fixed effects?\n\nControls for unobserved heterogeneity across individuals and over time\nFocuses on within-individual variation to identify treatment effects\nMore robust to omitted variable bias from time-invariant confounders"
  },
  {
    "objectID": "lectures/lecture_4.html#difference-in-differences-did-9",
    "href": "lectures/lecture_4.html#difference-in-differences-did-9",
    "title": "De Do Do Do, De Di i Di - Panel Data Methods",
    "section": "Difference-in-Differences (DiD)",
    "text": "Difference-in-Differences (DiD)\n2-way fixed effects model\n\n\n\nEstimation with fixed effects\n\n\n\n\nWhat changes with fixed effects?\n\nThe DiD estimate remains similar, indicating robustness to fixed effects\nControls for unobserved individual heterogeneity and time effects\nTime-invariant confounders are addressed (ability drops out!)\nBut what about standard errors?\n\n\n\n\n\nFor an exellent deep-dive into fixed effects models, see e.g. Breuer and DeHaan (2024) or Verbeek (2021)"
  },
  {
    "objectID": "lectures/lecture_4.html#difference-in-differences-did-10",
    "href": "lectures/lecture_4.html#difference-in-differences-did-10",
    "title": "De Do Do Do, De Di i Di - Panel Data Methods",
    "section": "Difference-in-Differences (DiD)",
    "text": "Difference-in-Differences (DiD)\nIdentification\nParallel trends assumption\n\n\nUnconditional means\n\n\n\n\n\n\n\n\n\n\nEvent study approach\n\n\n\n\n\n\n\n\nThe parallel trends assumption states that, in the absence of treatment, the average change in the outcome variable would have been the same for both the treatment and control groups."
  },
  {
    "objectID": "lectures/lecture_4.html#difference-in-differences-did-11",
    "href": "lectures/lecture_4.html#difference-in-differences-did-11",
    "title": "De Do Do Do, De Di i Di - Panel Data Methods",
    "section": "Difference-in-Differences (DiD)",
    "text": "Difference-in-Differences (DiD)\nStandard errors in DiD"
  },
  {
    "objectID": "lectures/lecture_4.html#difference-in-differences-did-12",
    "href": "lectures/lecture_4.html#difference-in-differences-did-12",
    "title": "De Do Do Do, De Di i Di - Panel Data Methods",
    "section": "Difference-in-Differences (DiD)",
    "text": "Difference-in-Differences (DiD)\nTakeaways so far\n\nDiD leverages both cross-sectional and time-series variation to identify causal effects (ATT)\nThe canonical DiD model can be extended with fixed effects to control for time-invariant heterogeneity\nThe parallel trends assumption is crucial for valid DiD inference\nProper standard error adjustments are essential for accurate inference in DiD settings\nIs that all? Not quite‚Ä¶\n\n\n\n\n\n\n\nLimitations\n\n\nLimitations arise in rollout (staggered) designs, where treatment timing varies across groups; TWFE can perform poorly in such settings (to be discussed later)."
  },
  {
    "objectID": "lectures/lecture_4.html#difference-in-differences-did-13",
    "href": "lectures/lecture_4.html#difference-in-differences-did-13",
    "title": "De Do Do Do, De Di i Di - Panel Data Methods",
    "section": "Difference-in-Differences (DiD)",
    "text": "Difference-in-Differences (DiD)\nStandard errors in DiD - Issues"
  },
  {
    "objectID": "lectures/lecture_4.html#difference-in-differences-did-14",
    "href": "lectures/lecture_4.html#difference-in-differences-did-14",
    "title": "De Do Do Do, De Di i Di - Panel Data Methods",
    "section": "Difference-in-Differences (DiD)",
    "text": "Difference-in-Differences (DiD)\nStandard errors in DiD - A new hope"
  },
  {
    "objectID": "lectures/lecture_4.html#difference-in-differences-did-15",
    "href": "lectures/lecture_4.html#difference-in-differences-did-15",
    "title": "De Do Do Do, De Di i Di - Panel Data Methods",
    "section": "Difference-in-Differences (DiD)",
    "text": "Difference-in-Differences (DiD)\nBeyond your MSc repliciation - Your contribution\nNew approaches\nHow to learn about the new approaches?\n(baker2022difference?)\nHow to learn about applicating them?\n\nA way to extend your MSc replication project is to apply some of the new DiD methods to the DiLLMa dataset and compare the results with the traditional TWFE approach."
  },
  {
    "objectID": "lectures/lecture_4.html#references",
    "href": "lectures/lecture_4.html#references",
    "title": "De Do Do Do, De Di i Di - Panel Data Methods",
    "section": "References",
    "text": "References\n\n\nBreuer, Matthias, and ED DeHaan. 2024. ‚ÄúUsing and Interpreting Fixed Effects Models.‚Äù Journal of Accounting Research 62 (4): 1183‚Äì1226.\n\n\nCinelli, Carlos, Andrew Forney, and Judea Pearl. 2024. ‚ÄúA Crash Course in Good and Bad Controls.‚Äù Sociological Methods & Research 53 (3): 1071‚Äì1104.\n\n\nHuntington-Klein, Nick. 2022. The Effect: An Introduction to Research Design and Causality. 2nd ed. Chapman; Hall/CRC.\n\n\nVerbeek, Marno. 2021. Panel Methods for Finance: A Guide to Panel Data Econometrics for Financial Applications. De Gruyter."
  },
  {
    "objectID": "lectures/lecture_2.html#data-exploration-and-visualization-1",
    "href": "lectures/lecture_2.html#data-exploration-and-visualization-1",
    "title": "Data Exploration and Visualization",
    "section": "Data Exploration and Visualization",
    "text": "Data Exploration and Visualization\nToday‚Äôs Journey\n\nWhy visualize? The power and peril\nDescribing variables: Building blocks\nDesign principles that matter\nTables: The unsung hero\n\nLiterature\n\nHuntington-Klein (2022) (Chapters 3 & 4)"
  },
  {
    "objectID": "lectures/lecture_2.html#data-exploration-and-visualization-2",
    "href": "lectures/lecture_2.html#data-exploration-and-visualization-2",
    "title": "Data Exploration and Visualization",
    "section": "Data Exploration and Visualization",
    "text": "Data Exploration and Visualization\nRecap - Where did we leave things?\n\n\nLast time: The Research Pipeline\n\n\nRaw & Clean Data\n\nData acquisition (WRDS, identifiers)\nMerging datasets (CUSIP, GVKEY, PERMNO)\nUnderstanding and creating tidy data\n\nToday‚Äôs Menu\n\nData exploration & visualization\nDescriptive statistics\nEffective communication of results\n\n\nToday we learn how to LOOK at what we‚Äôve built"
  },
  {
    "objectID": "lectures/lecture_2.html#data-exploration-and-visualization-3",
    "href": "lectures/lecture_2.html#data-exploration-and-visualization-3",
    "title": "Data Exploration and Visualization",
    "section": "Data Exploration and Visualization",
    "text": "Data Exploration and Visualization\nLearning Objectives\nBy the end of today, you will be able to\n\nExplain why visualization matters for research AND practice\nIdentify misleading visualizations and graph abuse\nDescribe distributions and relationships effectively\nApply core design principles to financial data\nCreate publication-quality summary statistics tables"
  },
  {
    "objectID": "lectures/lecture_2.html#why-visualize-the-power-and-peril-1",
    "href": "lectures/lecture_2.html#why-visualize-the-power-and-peril-1",
    "title": "Data Exploration and Visualization",
    "section": "Why Visualize? The Power and Peril",
    "text": "Why Visualize? The Power and Peril\nVisualization in Practice\n\n\nJust Eat Takeaway Analyst Presentation\n\n\n\n\n\n\nWhat do you notice?\n\n\n\n\n\n\nKey observation\n\n\nAlmost every slide contains a visualization!\n\n\n\n\n\n\n\n\n\nKey question\n\n\nWhy do they do this?\n\n\n\n\n\n\nFull presentation available here: Just Eat Takeaway H1 2022 Results"
  },
  {
    "objectID": "lectures/lecture_2.html#visualization-in-practice-1",
    "href": "lectures/lecture_2.html#visualization-in-practice-1",
    "title": "Data Exploration and Visualization",
    "section": "Visualization in Practice",
    "text": "Visualization in Practice\nGrowth Story\n\n\nGross Trsansaction Value Over Time\n\n\n\n\n\n\nWhat story does this tell?\n\n‚Äú~2X growth since pre-pandemic‚Äù\nClear trend, immediate impact\nVisual &gt; table of numbers\n\n\n\n\nWhat makes this effective?\n\nClean design\nClear annotation\nColor use to highlight key info"
  },
  {
    "objectID": "lectures/lecture_2.html#visualization-in-practice-2",
    "href": "lectures/lecture_2.html#visualization-in-practice-2",
    "title": "Data Exploration and Visualization",
    "section": "Visualization in Practice",
    "text": "Visualization in Practice\nGeographic Breakdown\n\n\nMarket Leadership Across Regions\n\n\n\n\n\n\nMultiple dimensions in one view\n\nGeography\nMarket position\nRevenue by segment\n\n\n\n\nCognitive efficiency?\n\nWould take paragraphs to describe in text\nLatest disclosures before takeover by Prosus ü§¶"
  },
  {
    "objectID": "lectures/lecture_2.html#visualization-in-practice-3",
    "href": "lectures/lecture_2.html#visualization-in-practice-3",
    "title": "Data Exploration and Visualization",
    "section": "Visualization in Practice",
    "text": "Visualization in Practice\nComparative Performance\n\n\nEBITDA by region over time\n\n\n\n\n\n\nWhat does this show?\n\nMultiple entities (regions)\nTime dimension\nPositive vs.¬†negative values\nClear color coding\n\n\n\n\nHow long would this table be?"
  },
  {
    "objectID": "lectures/lecture_2.html#why-visualize-the-power-and-peril-2",
    "href": "lectures/lecture_2.html#why-visualize-the-power-and-peril-2",
    "title": "Data Exploration and Visualization",
    "section": "Why Visualize? The Power and Peril",
    "text": "Why Visualize? The Power and Peril\nThe Case FOR Visualization\nWhat is visualization (vis)?\n\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively (Munzner 2025).\n\nWhy visualize?\n\nCommunication: Tell data-driven stories\nVerification: Confirm expected patterns\nExploration: Find unexpected patterns\nFalsification: Assess validity of models\n\n\n\nFor more theory and details on visualization analysis and design, see Munzner (2025)"
  },
  {
    "objectID": "lectures/lecture_2.html#why-visualize-the-power-and-peril-3",
    "href": "lectures/lecture_2.html#why-visualize-the-power-and-peril-3",
    "title": "Data Exploration and Visualization",
    "section": "Why Visualize? The Power and Peril",
    "text": "Why Visualize? The Power and Peril\nBut‚Ä¶ Visualization Can Mislead\n\n\n\n\n\n\n\nSource: Washington Post, 2025"
  },
  {
    "objectID": "lectures/lecture_2.html#why-visualize-the-power-and-peril-4",
    "href": "lectures/lecture_2.html#why-visualize-the-power-and-peril-4",
    "title": "Data Exploration and Visualization",
    "section": "Why Visualize? The Power and Peril",
    "text": "Why Visualize? The Power and Peril\nBut‚Ä¶ Visualization Can Mislead\nWhen keepin‚Äô it vis goes wrong\n\n\nOpenAI\n\n\n\n\n\n\nAnthropic"
  },
  {
    "objectID": "lectures/lecture_2.html#why-visualize-the-power-and-peril-5",
    "href": "lectures/lecture_2.html#why-visualize-the-power-and-peril-5",
    "title": "Data Exploration and Visualization",
    "section": "Why Visualize? The Power and Peril",
    "text": "Why Visualize? The Power and Peril\nBut‚Ä¶ Visualization Can Mislead\nWhen keepin‚Äô it vis goes wrong\n\n\nPizza toppings in the UK\n\n\n\n\n\n\nFemale height distribution"
  },
  {
    "objectID": "lectures/lecture_2.html#why-visualize-the-power-and-peril-6",
    "href": "lectures/lecture_2.html#why-visualize-the-power-and-peril-6",
    "title": "Data Exploration and Visualization",
    "section": "Why Visualize? The Power and Peril",
    "text": "Why Visualize? The Power and Peril\nInsights from Beattie and Jones (1992)\nThe use and abuse of graphs in annual reports: theoretical framework and empirical study\n\nStudy of 240 large UK companies‚Äô annual reports\nAverage: 5.9 graphs per report\nKey finding: Companies with ‚Äògood‚Äô performance significantly more likely to use graphs\nSelectivity: 65% graph at least one key financial variable\nBut which variables do they choose?"
  },
  {
    "objectID": "lectures/lecture_2.html#why-visualize-the-power-and-peril-7",
    "href": "lectures/lecture_2.html#why-visualize-the-power-and-peril-7",
    "title": "Data Exploration and Visualization",
    "section": "Why Visualize? The Power and Peril",
    "text": "Why Visualize? The Power and Peril\nTwo Forms of Distortion\nBeattie and Jones (1992) Framework\n\n\nSelectivity\nChoosing WHICH data to visualize\n\nGraph the good news, table the bad news\nExample: Graph revenue growth, table margin decline\n\n\nMeasurement distortion\nHOW data is presented\n\nAxis manipulation\nVisual exaggeration\nFound in 30% of graphs!\nAverage exaggeration: 10.7%"
  },
  {
    "objectID": "lectures/lecture_2.html#why-visualize-the-power-and-peril-8",
    "href": "lectures/lecture_2.html#why-visualize-the-power-and-peril-8",
    "title": "Data Exploration and Visualization",
    "section": "Why Visualize? The Power and Peril",
    "text": "Why Visualize? The Power and Peril\nDistortion Example Overview\n\n\n\n\n\n\n\nSource: Huang et al. (2011)"
  },
  {
    "objectID": "lectures/lecture_2.html#why-visualize-the-power-and-peril-9",
    "href": "lectures/lecture_2.html#why-visualize-the-power-and-peril-9",
    "title": "Data Exploration and Visualization",
    "section": "Why Visualize? The Power and Peril",
    "text": "Why Visualize? The Power and Peril\nAnscombe‚Äôs Quartet - The Famous Example\nIdentical Statistics, Different Stories\n\n\nAnscombe‚Äôs Quartet Data\n\n\n\n\n\n\nVariable\nN\nMean\nSD\nP0\nP25\nP50\nP75\nP100\n\n\n\n\nx1\n11\n9.0\n3.32\n4.00\n6.50\n9.00\n11.50\n14.00\n\n\ny1\n11\n7.5\n2.03\n4.26\n6.31\n7.58\n8.57\n10.84\n\n\nx2\n11\n9.0\n3.32\n4.00\n6.50\n9.00\n11.50\n14.00\n\n\ny2\n11\n7.5\n2.03\n3.10\n6.70\n8.14\n8.95\n9.26\n\n\nx3\n11\n9.0\n3.32\n4.00\n6.50\n9.00\n11.50\n14.00\n\n\ny3\n11\n7.5\n2.03\n5.39\n6.25\n7.11\n7.98\n12.74\n\n\nx4\n11\n9.0\n3.32\n8.00\n8.00\n8.00\n8.00\n19.00\n\n\ny4\n11\n7.5\n2.03\n5.25\n6.17\n7.04\n8.19\n12.50\n\n\n\n\n\n\n\nVisuals Matter\n\n\n\n\n\n\n\n\n\n\n\n\nVisual inspection also reveals differences in variance, outliers, and non-linearity that summary statistics miss. Helpful for model (OLS) diagnostics! Wait for it, Lecture 3."
  },
  {
    "objectID": "lectures/lecture_2.html#why-visualize-the-power-and-peril-10",
    "href": "lectures/lecture_2.html#why-visualize-the-power-and-peril-10",
    "title": "Data Exploration and Visualization",
    "section": "Why Visualize? The Power and Peril",
    "text": "Why Visualize? The Power and Peril\nAnscombe‚Äôs Quartet - The Famous Example\nKey Takeaways\n\nSummaries lose information\nDetails matter\nVisualization reveals structure that statistics hide"
  },
  {
    "objectID": "lectures/lecture_2.html#describing-variables",
    "href": "lectures/lecture_2.html#describing-variables",
    "title": "Data Exploration and Visualization",
    "section": "Describing Variables",
    "text": "Describing Variables\nTypes of Variables\n\n\nWhat according to Munzner (2025)\n\n\n\n\n\n\nWhat we typically deal with‚Ä¶\n\nContinuous: Price, returns, income\nCount: Number of mergers, trades\nOrdinal: Credit ratings (AAA, AA, A‚Ä¶)\nCategorical: Industry, country\nBinary: Default/no default"
  },
  {
    "objectID": "lectures/lecture_2.html#describing-variables-1",
    "href": "lectures/lecture_2.html#describing-variables-1",
    "title": "Data Exploration and Visualization",
    "section": "Describing Variables",
    "text": "Describing Variables\nUnderstanding Distributions\n\n\nCommon Distribution Shapes\n\n\n\n\n\n\n\n\n\n\nWhat is a distribution?\n\nThe pattern of values a variable can take\nKey question: How is the data spread out?\nExamples:\n\nAre most returns clustered around zero?\nDo some firms have extremely high market caps?\nIs income evenly distributed or skewed?"
  },
  {
    "objectID": "lectures/lecture_2.html#describing-variables-2",
    "href": "lectures/lecture_2.html#describing-variables-2",
    "title": "Data Exploration and Visualization",
    "section": "Describing Variables",
    "text": "Describing Variables\nVisualizing Distributions - Continuous Variables\n\n\nHistograms\n\n\n\n\n\n\n\n\n\n\nThe Classic Choice\n\nDivides data into bins\nHeight ‚Üí frequency in each bin"
  },
  {
    "objectID": "lectures/lecture_2.html#describing-variables-3",
    "href": "lectures/lecture_2.html#describing-variables-3",
    "title": "Data Exploration and Visualization",
    "section": "Describing Variables",
    "text": "Describing Variables\nVisualizing Distributions - Continuous Variables\n\n\nHistograms\n\n\n\n\n\n\n\n\n\n\nThe Classic Choice\n\nDivides data into bins\nHeight ‚Üí frequency in each bin\nDesign choices matter!:\n\nBin width too narrow ‚Üí noise\nBin width too wide ‚Üí oversmoothing"
  },
  {
    "objectID": "lectures/lecture_2.html#describing-variables-4",
    "href": "lectures/lecture_2.html#describing-variables-4",
    "title": "Data Exploration and Visualization",
    "section": "Describing Variables",
    "text": "Describing Variables\nVisualizing Distributions - Density Plots\n\n\n\n\n\n\n\n\n\n\n\n\nThe Smooth Alternative\n\nContinuous curve estimate\nNo arbitrary bin choices\nEasier to compare multiple distributions"
  },
  {
    "objectID": "lectures/lecture_2.html#describing-variables-5",
    "href": "lectures/lecture_2.html#describing-variables-5",
    "title": "Data Exploration and Visualization",
    "section": "Describing Variables",
    "text": "Describing Variables\nVisualizing Distributions - Density Plots\n\n\n\n\n\n\n\n\n\n\n\n\nThe Smooth Alternative\n\nContinuous curve estimate\nNo arbitrary bin choices\nEasier to compare multiple distributions"
  },
  {
    "objectID": "lectures/lecture_2.html#describing-variables-6",
    "href": "lectures/lecture_2.html#describing-variables-6",
    "title": "Data Exploration and Visualization",
    "section": "Describing Variables",
    "text": "Describing Variables\nThe Numbers Behind the Picture\nSummary Statistics\n\n\nLocation (central tendency)\n\nMean: Average value\nMedian: 50th percentile\nMode: Most frequent value\n\n\nSpread (variability):\n\nStandard deviation: Average distance from mean\nVariance: SD squared\nRange: Max - Min\nInterquartile range (IQR): Q3 - Q1\n\n\nPercentile\n‚Üí value below which X% of observations fall\nExamples:\n\n25th percentile (Q1): Bottom quarter\n50th percentile (Median): Middle\n75th percentile (Q3): Top quarter\n1st/99th percentile: Extreme values (outliers?)\n\n\nPutting it all together (Box Plot)"
  },
  {
    "objectID": "lectures/lecture_2.html#describing-variables-7",
    "href": "lectures/lecture_2.html#describing-variables-7",
    "title": "Data Exploration and Visualization",
    "section": "Describing Variables",
    "text": "Describing Variables\nDescribing Relationships Between Variables\nMoving Beyond Univariate Analysis\n\n\nKey questions\n\nHow do two variables move together?\nIs there a pattern?\nIs the relationship linear or nonlinear?\n\n\nTools\n\nScatter plots\nCorrelation\nTime series plots (for temporal relationships)"
  },
  {
    "objectID": "lectures/lecture_2.html#describing-variables-8",
    "href": "lectures/lecture_2.html#describing-variables-8",
    "title": "Data Exploration and Visualization",
    "section": "Describing Variables",
    "text": "Describing Variables\nDescribing Relationships Between Variables\nThe Scatter Plot\n\n\nTwo Continuous Variables\n\n\n\n\n\n\n\n\n\n\nWhat to look for\n\nDirection (positive/negative)\nStrength (tight cluster vs.¬†diffuse)\nLinearity (straight line or curve?)\nOutliers"
  },
  {
    "objectID": "lectures/lecture_2.html#describing-variables-9",
    "href": "lectures/lecture_2.html#describing-variables-9",
    "title": "Data Exploration and Visualization",
    "section": "Describing Variables",
    "text": "Describing Variables\nDescribing Relationships Between Variables\nConditional Relationships\n\n\n\n\n\n\n\n\n\nTerm\nMeaning\nExample\n\n\n\n\nUnconditional (or marginal) distribution\nThe overall spread of a variable, ignoring all other variables.\nHeight distribution of all children.\n\n\nConditional distribution\nThe spread of one variable given a specific value of another variable.\nDistributions of vitamin‚ÄØE intake among those who exercise vigorously versus those who do not.\n\n\nUnconditional mean\nThe average value of a variable, ignoring all other variables.\nAverage height of all children.\n\n\nConditional mean\nThe average value of a variable given a specific value of another variable.\nAverage vitamin‚ÄØE intake among those who exercise vigorously versus those who do not.\n\n\n\n\n\n\nSource: Adapted from Huntington-Klein (2022), Ch. 4"
  },
  {
    "objectID": "lectures/lecture_2.html#describing-variables-10",
    "href": "lectures/lecture_2.html#describing-variables-10",
    "title": "Data Exploration and Visualization",
    "section": "Describing Variables",
    "text": "Describing Variables\nDescribing Relationships Between Variables\nCorrelation vs.¬†Causation\n\n\nCorrelation vs.¬†Causation\n\n\n\n\n\n\nThe Most Important Distinction in Statistics\n\nCorrelation: X and Y move together\nCausation: X causes Y\n\n\n\n\nMore on that during Lecture 3 (identification)"
  },
  {
    "objectID": "lectures/lecture_2.html#describing-variables-11",
    "href": "lectures/lecture_2.html#describing-variables-11",
    "title": "Data Exploration and Visualization",
    "section": "Describing Variables",
    "text": "Describing Variables\nDescribing Relationships Between Variables\nTime Series Plots\n\n\nDaily Study Hours Over Time‚Äù\n\n\n\n\n\n\n\n\n\n\nBasics of Time Series Plots\n\nX-axis: Time\nY-axis: Variable of interest\nConnect the dots in chronological order\n\nEssential for ‚Ä¶\n\nEvent studies (Lecture 5)\n(Parallel) Trend analysis (Lecture 4)\nStructural breaks\nSeasonality"
  },
  {
    "objectID": "lectures/lecture_2.html#describing-variables-12",
    "href": "lectures/lecture_2.html#describing-variables-12",
    "title": "Data Exploration and Visualization",
    "section": "Describing Variables",
    "text": "Describing Variables\nDescribing Relationships Between Variables\nMultiple Time Series - Comparison\n\n\nVW vs.¬†Competitors - TEASER A2\n\n\nWhat this reveals\n\nContagion effects\nRelative performance\nIndustry-wide vs.¬†firm-specific shocks"
  },
  {
    "objectID": "lectures/lecture_2.html#design-principles-that-matter-1",
    "href": "lectures/lecture_2.html#design-principles-that-matter-1",
    "title": "Data Exploration and Visualization",
    "section": "Design Principles That Matter",
    "text": "Design Principles That Matter\nMunzner (2025)‚Äôs Visualization Framework (Simplified)\n\n\nMunzner (2025)\n\n\n\n\n\n\nThree Important Questions\nWhat? - What data do I have?\n\nTables, networks, time series, spatial data\nWe mostly work with: Tables (panel data)"
  },
  {
    "objectID": "lectures/lecture_2.html#design-principles-that-matter-2",
    "href": "lectures/lecture_2.html#design-principles-that-matter-2",
    "title": "Data Exploration and Visualization",
    "section": "Design Principles That Matter",
    "text": "Design Principles That Matter\nMunzner (2025)‚Äôs Visualization Framework (Simplified)\n\n\nMunzner (2025)\n\n\n\n\n\n\nThree Important Questions\nWhat? - What data do I have?\n\nTables, networks, time series, spatial data\nWe mostly work with: Tables (panel data)\n\nWhy? - Why am I visualizing?\n\nCommunication, exploration, verification"
  },
  {
    "objectID": "lectures/lecture_2.html#sesign-principles-that-matter",
    "href": "lectures/lecture_2.html#sesign-principles-that-matter",
    "title": "Data Exploration and Visualization",
    "section": "Sesign Principles That Matter",
    "text": "Sesign Principles That Matter\nMunzner (2025)‚Äôs Visualization Framework (Simplified)\n\n\nMunzner (2025)\n\n\n\n\n\n\nThree Important Questions\nWhat? - What data do I have?\n\nTables, networks, time series, spatial data\nWe mostly work with: Tables (panel data)\n\nWhy?- Why am I visualizing?\n\nCommunication, exploration, verification\n\nHow? - How should I encode the data?\n\nPosition, color, size, shape"
  },
  {
    "objectID": "lectures/lecture_2.html#design-principles-that-matter-3",
    "href": "lectures/lecture_2.html#design-principles-that-matter-3",
    "title": "Data Exploration and Visualization",
    "section": "Design Principles That Matter",
    "text": "Design Principles That Matter\nThe Data-Ink Ratio\nEdward Tufte‚Äôs Core Principle\n\\[ \\text{Data-ink ratio} = \\frac{\\text{ink used to display data}}{\\text{total ink used}}\\]\n\n\nGoal: Maximize this ratio\n\nRemove chart junk\nEliminate non-data ink\nLet the data speak\n\n\nExample\n\n\n\nSource"
  },
  {
    "objectID": "lectures/lecture_2.html#design-principles-that-matter-4",
    "href": "lectures/lecture_2.html#design-principles-that-matter-4",
    "title": "Data Exploration and Visualization",
    "section": "Design Principles That Matter",
    "text": "Design Principles That Matter\nChoosing the Right Plot Type\nMatch Visualization to Data Structure\n\n\n\n\nData Structure\nBest Visualization\n\n\n\n\nOne continuous variable\nHistogram, density plot, box plot\n\n\nOne categorical variable\nBar chart\n\n\nTwo continuous variables\nScatter plot\n\n\nContinuous over time\nLine plot\n\n\nMultiple groups over time\nLine plot or small multiples\n\n\nPart-to-whole\nStacked bar (avoid pie charts!)\n\n\n\n\n\n\nThis is a simplified refernce guide for your covience; real-world data may require hybrid approaches."
  },
  {
    "objectID": "lectures/lecture_2.html#design-principles-that-matter-5",
    "href": "lectures/lecture_2.html#design-principles-that-matter-5",
    "title": "Data Exploration and Visualization",
    "section": "Design Principles That Matter",
    "text": "Design Principles That Matter\nColor Theory Basics\nStrategic Use of Color\nThree palette types:\n\nSequential: Light to dark (e.g., revenue growth)\nDiverging: Two-color scale with neutral middle (e.g., positive/negative returns)\nCategorical: Distinct colors for groups (e.g., different firms)\n\n\n\n\n\n\n\n\nRule\n\n\nUse color to enhance, not decorate"
  },
  {
    "objectID": "lectures/lecture_2.html#design-principles-that-matter-6",
    "href": "lectures/lecture_2.html#design-principles-that-matter-6",
    "title": "Data Exploration and Visualization",
    "section": "Design Principles That Matter",
    "text": "Design Principles That Matter\nAccessibility - Colorblind Considerations\n~8% of men have color vision deficiency\n\nAvoid red-green combinations\nUse colorblind-safe palettes:\n\nViridis (sequential)\nColorBrewer (all types)\n\n\n\n\nMake sure your visualizations are interpretable by everyone! (inclusivity matters)"
  },
  {
    "objectID": "lectures/lecture_2.html#design-principles-that-matter-7",
    "href": "lectures/lecture_2.html#design-principles-that-matter-7",
    "title": "Data Exploration and Visualization",
    "section": "Design Principles That Matter",
    "text": "Design Principles That Matter\nAccessibility - Colorblind Considerations\n~8% of men have color vision deficiency\n\n\nAvoid red-green combinations\n\n\n\n\n\n\n\n\n\n\nUse colorblind-safe palettes: Viridis"
  },
  {
    "objectID": "lectures/lecture_2.html#design-principles-that-matter-8",
    "href": "lectures/lecture_2.html#design-principles-that-matter-8",
    "title": "Data Exploration and Visualization",
    "section": "Design Principles That Matter",
    "text": "Design Principles That Matter\nAxis Integrity\nY-axis should start at zero for bar charts\n\n\nExceptions\n\nLine plots (time series can start at sensible minimum)\nWhen showing small changes in large numbers\nBUT: Always be transparent about scale choices\n\n\nBest practice\n\nUse non-zero axis when changes matter\nBUT: Clearly label and acknowledge the choice\nNever hide the axis range"
  },
  {
    "objectID": "lectures/lecture_2.html#design-principles-that-matter-9",
    "href": "lectures/lecture_2.html#design-principles-that-matter-9",
    "title": "Data Exploration and Visualization",
    "section": "Design Principles That Matter",
    "text": "Design Principles That Matter\nTypography Matters\n\\[ \\text{Readable} &gt; \\text{Beautiful} \\]\n\n\nFont guidelines\n\nMinimum size: 8pt for print, 12pt for presentations\nFont families:\n\nSans-serif for plots (Arial, Helvetica)\nSerif for text if desired (Times, Garamond)\n\nConsistency: Use same fonts throughout paper/presentation\n\n\nLabels\n\nAxis labels: Clear, concise\nTitle: Informative, standalone\nLegend: Only if necessary (prefer direct labels)"
  },
  {
    "objectID": "lectures/lecture_2.html#design-principles-that-matter-10",
    "href": "lectures/lecture_2.html#design-principles-that-matter-10",
    "title": "Data Exploration and Visualization",
    "section": "Design Principles That Matter",
    "text": "Design Principles That Matter\nThe Iteration Process"
  },
  {
    "objectID": "lectures/lecture_2.html#tables-1",
    "href": "lectures/lecture_2.html#tables-1",
    "title": "Data Exploration and Visualization",
    "section": "Tables",
    "text": "Tables\nThe Unsung Hero of Academic Communication\n\n\nTables are better when‚Ä¶\n\nExact values matter (not just patterns)\nMany variables to compare\nFormal hypothesis testing results\nStandard format expected (e.g., regression output)\n\n\nPlots are better when‚Ä¶\n\nPattern matters more than precision\nLarge amounts of data\nRelationships are key"
  },
  {
    "objectID": "lectures/lecture_2.html#tables-2",
    "href": "lectures/lecture_2.html#tables-2",
    "title": "Data Exploration and Visualization",
    "section": "Tables",
    "text": "Tables\nThe Unsung Hero of Academic Communication\nSummary Statistics Table - Anatomy\nStandard Format (imo)\n\n\n\nVariable\nN\nMean\nSD\nMin\nP25\nMedian\nP75\nMax\n\n\n\n\n\n\n\nWhat this shows\n\nN: Sample size (are there missing values?)\nMean: Central tendency\nSD: Dispersion\nMin/Max: Range (outliers?)\nPercentiles: Distribution shape\n\n\nWhat to include\n\nDependent variable(s)\nKey All other variables\nIf panel data: Note firm-year structure\nNotes on data source, transformations, etc.\nAdhere to journal/MSc thesis style guide"
  },
  {
    "objectID": "lectures/lecture_2.html#tables-3",
    "href": "lectures/lecture_2.html#tables-3",
    "title": "Data Exploration and Visualization",
    "section": "Tables",
    "text": "Tables\nTable Design Principles\nMaking Tables Readable\n\n\nAlignment\n\nNumbers: Right-align\nText: Left-align\nHeaders: Center acceptable\n\n\nPrecision\n\n2-3 decimal places usually sufficient\nBe consistent across columns\nConsistent between coefficients and fit stats\n\n\n\n\nFormatting\n\nUse rules (horizontal lines) sparingly\nWhite space is your friend\nBold for emphasis (e.g., column headers)\n\n\nNotes\n\nDefine variables\nExplain sample restrictions\nNote data sources"
  },
  {
    "objectID": "lectures/lecture_2.html#tables-4",
    "href": "lectures/lecture_2.html#tables-4",
    "title": "Data Exploration and Visualization",
    "section": "Tables",
    "text": "Tables\nTable Design Principles\nExample & Teaser for Assignment 6\n\nHuck (2024), Table 2"
  },
  {
    "objectID": "lectures/lecture_2.html#takeaways-1",
    "href": "lectures/lecture_2.html#takeaways-1",
    "title": "Data Exploration and Visualization",
    "section": "Takeaways",
    "text": "Takeaways\nWhat to Remember\n\nVisualization is powerful - for communication AND deception\nDescribe first, model later - understand distributions and relationships\nDesign principles matter - data-ink ratio, color, accessibility\nTables are essential - especially in academic work\nIteration improves quality - first draft is never the last draft\n\n\n\n\n\n\n\nThe big picture\n\n\nGood visualization and tables are core skills, not optional extras."
  },
  {
    "objectID": "lectures/lecture_2.html#next-week-preview",
    "href": "lectures/lecture_2.html#next-week-preview",
    "title": "Data Exploration and Visualization",
    "section": "Next Week Preview",
    "text": "Next Week Preview\nRegression Methods and Identification\nBuilding on today\n\nWe can now DESCRIBE data\nNext: We learn to MODEL relationships\nOLS assumptions\nWhat is identification?\nEndogeneity and causation\n\nThe connection\n\nToday: ‚ÄúWhat does the data show?‚Äù\nNext week: ‚ÄúWhat does it mean?‚Äù"
  },
  {
    "objectID": "lectures/lecture_2.html#references",
    "href": "lectures/lecture_2.html#references",
    "title": "Data Exploration and Visualization",
    "section": "References",
    "text": "References\n\n\nBeattie, Vivien, and Michael John Jones. 1992. ‚ÄúThe Use and Abuse of Graphs in Annual Reports: Theoretical Framework and Empirical Study.‚Äù Accounting and Business Research 22 (88): 291‚Äì303.\n\n\nHuang, Shaio-Yan, Shi-Ming Huang, Tung-Hsien Wu, and Tung-Yen Hsieh. 2011. ‚ÄúThe Data Quality Evaluation of Graph Information.‚Äù Journal of Computer Information Systems 51 (4): 81‚Äì91.\n\n\nHuck, John R. 2024. ‚ÄúThe Psychological Externalities of Investing: Evidence from Stock Returns and Crime.‚Äù The Review of Financial Studies 37 (7): 2273‚Äì2314.\n\n\nHuntington-Klein, Nick. 2022. The Effect: An Introduction to Research Design and Causality. 2nd ed. Chapman; Hall/CRC.\n\n\nMunzner, Tamara. 2025. ‚ÄúVisualization Analysis and Design.‚Äù In Proceedings of the Special Interest Group on Computer Graphics and Interactive Techniques Conference Courses, 1‚Äì2."
  },
  {
    "objectID": "lectures/lecture_2.html#appendix-1",
    "href": "lectures/lecture_2.html#appendix-1",
    "title": "Data Exploration and Visualization",
    "section": "Appendix",
    "text": "Appendix\nTypes of Variables\n\n\n\n\n\n\n\n\n\n\nType\nWhat it represents\nKey characteristics\nTypical examples\n\n\n\n\nContinuous\nReal‚Äëvalued measurements that can take any value within a range (often infinite).\nNo natural ‚Äúnext‚Äù value; can be split to arbitrary precision.\nMonthly income, height, temperature.\n\n\nCount\nNon‚Äënegative integers recording counts of occurrences.\nCannot be negative; usually discrete, but can sometimes be treated as continuous when counts are large.\nNumber of mergers in a year, number of accidents.\n\n\nOrdinal\nCategories with a meaningful order but unknown spacing.\n‚ÄúHigher‚Äù vs ‚Äúlower‚Äù is defined but not how much higher.\nNeuroticism level (low‚ÄØ/‚ÄØmedium‚ÄØ/‚ÄØhigh), education level.\n\n\nCategorical (nominal)\nDistinct, unordered categories.\nNo inherent ordering.\nFlower colour, blood type, eye colour.\n\n\nBinary\nSpecial case of categorical with exactly two possible values (often ‚Äúyes‚Äù/‚Äúno‚Äù).\nSimplifies analysis; can be expanded into several binary variables.\nMilitary service (yes/no), treatment assignment.\n\n\nQualitative\nText, images, or other non‚Äënumeric information that cannot be straightforwardly categorised.\nRequires transformation or summarisation before quantitative analysis.\nNewspaper headline, interview transcript.\n\n\n\n\n\n\n\nSource: Adapted from Huntington-Klein (2022), Ch. 3"
  },
  {
    "objectID": "lectures/lecture_2.html#appendix-2",
    "href": "lectures/lecture_2.html#appendix-2",
    "title": "Data Exploration and Visualization",
    "section": "Appendix",
    "text": "Appendix\nPlot types overview\nProportions\n\n\n\n\n\nSingle Distribution"
  },
  {
    "objectID": "lectures/lecture_2.html#appendix-3",
    "href": "lectures/lecture_2.html#appendix-3",
    "title": "Data Exploration and Visualization",
    "section": "Appendix",
    "text": "Appendix\nPlot types overview\nMultiple Distributions"
  },
  {
    "objectID": "lectures/lecture_2.html#appendix-4",
    "href": "lectures/lecture_2.html#appendix-4",
    "title": "Data Exploration and Visualization",
    "section": "Appendix",
    "text": "Appendix\nPlot types overview\nProportions - 2 + Groups"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Analytics for Finance",
    "section": "",
    "text": "Welcome to the Data Analytics for Finance course materials. This website contains all the lecture slides, assignments, and resources for the course.\n\n\nThis course is designed to equip students with comprehensive data analysis skills using Stata and a thorough understanding of research methods in finance. The course emphasizes both theoretical foundations and practical implementation of econometric techniques essential for empirical finance research.\nStudents will learn how to apply statistical analysis techniques with proper understanding of underlying assumptions, interpret data effectively, and address common methodological challenges in financial research. These skills directly support students‚Äô ability to successfully complete their master thesis replication projects and prepare them for data-intensive roles in the financial industry.\n\n\n\nBy the end of this course, students will be able to:\n\nData Management: Clean, transform, and merge complex datasets using different identifiers (CUSIP, GVKEY, PERMNO) in Stata\nEconometric Theory: Understand and verify the assumptions underlying statistical methods used in finance research\nPanel Methods: Implement and interpret fixed effects models with appropriate standard error corrections\nCausal Inference: Apply difference-in-differences and event study methodologies to identify causal effects\nResearch Communication: Create publication-quality tables and visualizations for effective presentation of empirical findings\nReplication Skills: Execute replications of published research with proper documentation and Stata code\n\n\n\n\nThe course consists of 6 sessions, each lasting 2 hours 45 minutes. The sessions will be held in person on campus. The course includes individual assignments that reinforce the concepts learned in class.\n\n\n\n\nFrom Messy Data to Research Insights\nData Exploration and Visualization\nRegressions and Identification\nDe Do Do Do, De Di i Di - Panel Data Methods\nEvent Studies (CAR) and Fama‚ÄìMacBeth\nReplication Workshop\n\n\n\n\n\n\nCanvas will be used for announcements and sharing of resources.\n\n\n\nAll lecture slides, and additional resources are available on this website. Students are encouraged to review the materials before and after each session to reinforce their understanding.\n\n\n\nAssignments will be available via Jupyter Hub. You will receive a personal invitation to access the platform via Canvas.\n\n\n\n\n\n\n\nSix assignments throughout the course\nAll assignments must be completed\n\n\n\n\n\nDieselgate - Data Wrangling\nDieselgate - Data Visualization\nDieselgate - Regression Analysis\nDieselgate - Difference-in-Differences\nDieselgate - Event Study\nReplication Exercise - Replicating a Published Study with a Twist\n\n\n\n\n\nOverall course grade ‚â• 5.5\nAssignmentgrade ‚â• 50%\n5 out of 6 assignments must be submitted and passed, i.e.¬†‚â• 50%\n\n\n\n\n\nStudents will use:\n\nStata (version 17 or higher) - All econometric analysis\nData from financial databases available through university subscriptions\n\nAll software is available through university resources. Basic familiarity with statistics is expected.\n\n\n\n\n\n\nHuntington-Klein, N. (2022). The Effect: An Introduction to Research Design and Causality (2nd ed.). Chapman and Hall/CRC.\n\nFree online version available at theeffectbook.net\nRequired reading for causal inference concepts\nSpecific chapters assigned for each session\n\n\nAdditional resources, recommended readings, and useful links."
  },
  {
    "objectID": "index.html#course-outline",
    "href": "index.html#course-outline",
    "title": "Data Analytics for Finance",
    "section": "",
    "text": "This course is designed to equip students with comprehensive data analysis skills using Stata and a thorough understanding of research methods in finance. The course emphasizes both theoretical foundations and practical implementation of econometric techniques essential for empirical finance research.\nStudents will learn how to apply statistical analysis techniques with proper understanding of underlying assumptions, interpret data effectively, and address common methodological challenges in financial research. These skills directly support students‚Äô ability to successfully complete their master thesis replication projects and prepare them for data-intensive roles in the financial industry."
  },
  {
    "objectID": "index.html#learning-goals",
    "href": "index.html#learning-goals",
    "title": "Data Analytics for Finance",
    "section": "",
    "text": "By the end of this course, students will be able to:\n\nData Management: Clean, transform, and merge complex datasets using different identifiers (CUSIP, GVKEY, PERMNO) in Stata\nEconometric Theory: Understand and verify the assumptions underlying statistical methods used in finance research\nPanel Methods: Implement and interpret fixed effects models with appropriate standard error corrections\nCausal Inference: Apply difference-in-differences and event study methodologies to identify causal effects\nResearch Communication: Create publication-quality tables and visualizations for effective presentation of empirical findings\nReplication Skills: Execute replications of published research with proper documentation and Stata code"
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Data Analytics for Finance",
    "section": "",
    "text": "The course consists of 6 sessions, each lasting 2 hours 45 minutes. The sessions will be held in person on campus. The course includes individual assignments that reinforce the concepts learned in class."
  },
  {
    "objectID": "index.html#lectures",
    "href": "index.html#lectures",
    "title": "Data Analytics for Finance",
    "section": "",
    "text": "From Messy Data to Research Insights\nData Exploration and Visualization\nRegressions and Identification\nDe Do Do Do, De Di i Di - Panel Data Methods\nEvent Studies (CAR) and Fama‚ÄìMacBeth\nReplication Workshop"
  },
  {
    "objectID": "index.html#materials",
    "href": "index.html#materials",
    "title": "Data Analytics for Finance",
    "section": "",
    "text": "Canvas will be used for announcements and sharing of resources.\n\n\n\nAll lecture slides, and additional resources are available on this website. Students are encouraged to review the materials before and after each session to reinforce their understanding.\n\n\n\nAssignments will be available via Jupyter Hub. You will receive a personal invitation to access the platform via Canvas."
  },
  {
    "objectID": "index.html#assessment",
    "href": "index.html#assessment",
    "title": "Data Analytics for Finance",
    "section": "",
    "text": "Six assignments throughout the course\nAll assignments must be completed\n\n\n\n\n\nDieselgate - Data Wrangling\nDieselgate - Data Visualization\nDieselgate - Regression Analysis\nDieselgate - Difference-in-Differences\nDieselgate - Event Study\nReplication Exercise - Replicating a Published Study with a Twist\n\n\n\n\n\nOverall course grade ‚â• 5.5\nAssignmentgrade ‚â• 50%\n5 out of 6 assignments must be submitted and passed, i.e.¬†‚â• 50%"
  },
  {
    "objectID": "index.html#software-and-tools",
    "href": "index.html#software-and-tools",
    "title": "Data Analytics for Finance",
    "section": "",
    "text": "Students will use:\n\nStata (version 17 or higher) - All econometric analysis\nData from financial databases available through university subscriptions\n\nAll software is available through university resources. Basic familiarity with statistics is expected."
  },
  {
    "objectID": "index.html#resources",
    "href": "index.html#resources",
    "title": "Data Analytics for Finance",
    "section": "",
    "text": "Huntington-Klein, N. (2022). The Effect: An Introduction to Research Design and Causality (2nd ed.). Chapman and Hall/CRC.\n\nFree online version available at theeffectbook.net\nRequired reading for causal inference concepts\nSpecific chapters assigned for each session\n\n\nAdditional resources, recommended readings, and useful links."
  },
  {
    "objectID": "lectures/lecture_1.html#introduction-1",
    "href": "lectures/lecture_1.html#introduction-1",
    "title": "From Messy Data to Research Insights",
    "section": "Introduction",
    "text": "Introduction\nWho am I?\n\n\n\n\n \n\n\n\nCaspar David Peter\n\n\nüè¢ ¬† ¬† Rotterdam School of Management\n\n\nüë∑ ¬† ¬† Associate Professor\n\n\nüè´ ¬† ¬† Doctorate (WHU)\n\n\nüè´ ¬† ¬† Dipl.-√ñk. (RUB)\n\n\nüë∂ ¬† ¬† Bochum, Germany\n\n\nüè† ¬† ¬† Rotterdam, Netherlands\n\n\nüçûüßà Economic consequences of transparency"
  },
  {
    "objectID": "lectures/lecture_1.html#setting-the-stage-1",
    "href": "lectures/lecture_1.html#setting-the-stage-1",
    "title": "From Messy Data to Research Insights",
    "section": "Setting the Stage",
    "text": "Setting the Stage\nWhy are we here?\n\n\nThe struggle is real\n\n\nWhat we gonna do about it?\n\nL1-2: Data wrangling & visualization (the foundation)\nL3-4: Regression & panel methods (the workhorse)\nL5: Event studies & Fama-MacBeth (specialized tools)\nL6: Replication workshop (putting it together)"
  },
  {
    "objectID": "lectures/lecture_1.html#setting-the-stage-2",
    "href": "lectures/lecture_1.html#setting-the-stage-2",
    "title": "From Messy Data to Research Insights",
    "section": "Setting the Stage",
    "text": "Setting the Stage\nLogistics\n\n\nLectures\n\nDates & Times & Rooms: Timetable\nFomat: 6 √ó ~ 3-hour sessions\nNo mandatory attendance, but highly recommended!\n\n\nResources\n\nCourse Canvas page\nCourse website\nTextbooks: Huntington-Klein (2022) and Verbeek (2021)\nRequired readings (see lecture slides)"
  },
  {
    "objectID": "lectures/lecture_1.html#setting-the-stage-3",
    "href": "lectures/lecture_1.html#setting-the-stage-3",
    "title": "From Messy Data to Research Insights",
    "section": "Setting the Stage",
    "text": "Setting the Stage\nLogistics\n\n\nAssignments\n\n6 assignments (weekly, after each lecture)\nAssignment 6 is a ‚Äúreplication‚Äù project\nAccess via browser (JupyterHub)\nNo local installation needed!\nDeadlines/Details in assignment documents\n\n\nHow to succeed\n\n\nComplete assignments on time \nPass/Fail: Assignments completion (equally weighted), i.e.¬†grade = 5.5\n\n1 ‚Äújoker‚Äù assignment allowed\nFail if &gt;1 assignment missing or not submitted on time\nFail if overall assignmnet score &lt; 5.5"
  },
  {
    "objectID": "lectures/lecture_1.html#setting-the-stage-4",
    "href": "lectures/lecture_1.html#setting-the-stage-4",
    "title": "From Messy Data to Research Insights",
    "section": "Setting the Stage",
    "text": "Setting the Stage\nPhilosophy of the course\n\nThis is NOT a coding course!\n\n\n\nWhat this course is NOT\n\nA Stata coding tutorial\nA software certification\nAbout memorizing syntax\n\n\nWhat this course IS\n\nA course about research design and empirical methods\nLearning how to think about data and causality EVERYWHERE\nUnderstanding what steps you need to take and why\nA fallback when you get stuck in your thesis work"
  },
  {
    "objectID": "lectures/lecture_1.html#setting-the-stage-5",
    "href": "lectures/lecture_1.html#setting-the-stage-5",
    "title": "From Messy Data to Research Insights",
    "section": "Setting the Stage",
    "text": "Setting the Stage\nElephant in the room: Stata\nThe role of coding\n\nImplementation is how we deepen understanding\nHands-on practice makes abstract concepts concrete\nBut if you understand the concepts, you can implement in any language (Python, R, Stata, Julia‚Ä¶)\n\nWhy Stata?\n\nResearch lingua franca in finance/accounting‚Äîmost papers use it\nYour thesis supervisor likely uses it\nReplication packages are overwhelmingly in Stata"
  },
  {
    "objectID": "lectures/lecture_1.html#setting-the-stage-6",
    "href": "lectures/lecture_1.html#setting-the-stage-6",
    "title": "From Messy Data to Research Insights",
    "section": "Setting the Stage",
    "text": "Setting the Stage\nTakeaway\n\nIf you understand what you‚Äôre trying to do and why, the coding is the easy part. If you don‚Äôt understand the research design, no amount of syntax knowledge will save you.\n\nOn (NOT) using LLMs\n\nThe course manual is clear on this topic\n‚Äú‚Ä¶if you don‚Äôt understand what you‚Äôre asking for, you won‚Äôt know if the answer is right.‚Äù\nCan I check if you used LLMs? No.\nBut latest during your thesis writing and defense, it will show if you don‚Äôt understand what you did."
  },
  {
    "objectID": "lectures/lecture_1.html#setting-the-stage-7",
    "href": "lectures/lecture_1.html#setting-the-stage-7",
    "title": "From Messy Data to Research Insights",
    "section": "Setting the Stage",
    "text": "Setting the Stage\nCore Skills 2025 - World Economic Forum\n\nFuture of Jobs Report2025"
  },
  {
    "objectID": "lectures/lecture_1.html#organizing-research-2",
    "href": "lectures/lecture_1.html#organizing-research-2",
    "title": "From Messy Data to Research Insights",
    "section": "Organizing Research",
    "text": "Organizing Research\nYour future self will thank you!\n\n\nProject structure\n\n\nKey principles (adjust to your needs)\n\nRaw data is sacred‚Äînever modify it directly\nRunning order, e.g.¬†number your scripts in execution order\nOne script = one purpose\nDocument every decision that involves judgment in the code with comments"
  },
  {
    "objectID": "lectures/lecture_1.html#organizing-research-3",
    "href": "lectures/lecture_1.html#organizing-research-3",
    "title": "From Messy Data to Research Insights",
    "section": "Organizing Research",
    "text": "Organizing Research\nReproducibility & Quarto\n\n\nThesis requirements\n\nGoal: Replicability of the scientific results\nAll steps from raw data to final results must be documented\nMSc thesis ideally one source file (e.g., ‚Äú.qmd‚Äù file)\n\nIncludes code, output, and narrative (references, etc.)\n\nMore details in the thesis manual!\n\n\nAssignments\n\nAssignments are on JupyterHub\n\n‚Äú.ipynb‚Äù files (Jupyter Notebooks)\nRun code cells interactively in the browser\n\nFollow same principles as for thesis work\n\nThey combine code, output, and narrative\nRun from top to bottom to reproduce results\n\nAssignments mimick thesis workflow as closely as possible"
  },
  {
    "objectID": "lectures/lecture_1.html#organizing-research-4",
    "href": "lectures/lecture_1.html#organizing-research-4",
    "title": "From Messy Data to Research Insights",
    "section": "Organizing Research",
    "text": "Organizing Research\nStata, Python, and Quarto"
  },
  {
    "objectID": "lectures/lecture_1.html#data-structure-tidy-data-1",
    "href": "lectures/lecture_1.html#data-structure-tidy-data-1",
    "title": "From Messy Data to Research Insights",
    "section": "Data Structure & Tidy Data",
    "text": "Data Structure & Tidy Data\nWhat is tidy data?\n\n\n\n\n\n\nDefinition\n\n\n\nEach variable is a column\nEach observation is a row\nEach type of observational unit is a table\n\n\n\n\nWhy is tidy data important?\n\nAlmost every statistical command expects tidy data\n(Data) Cleaning means getting from raw to tidy data\nEasier to understand, document, and share"
  },
  {
    "objectID": "lectures/lecture_1.html#data-structure-tidy-data-2",
    "href": "lectures/lecture_1.html#data-structure-tidy-data-2",
    "title": "From Messy Data to Research Insights",
    "section": "Data Structure & Tidy Data",
    "text": "Data Structure & Tidy Data\nTidy versus ‚Äúmessy‚Äù data\n\n\n‚ÄúMessy‚Äù data (wide format)\n\n\n\n\nStudent ID\nScore_22\nScore_23\nScore_2024\n\n\n\n\nS001abc\n85\n90.0\n92.0\n\n\nS002_\n78.0\n81\n85\n\n\nS 003\n92\n95\n98.0\n\n\n\n\n\nTidy data (long format)\n\n\n\n\nStudent ID\nYear\nScore\n\n\n\n\nS001\n2022\n85\n\n\nS001\n2023\n90\n\n\nS001\n2024\n92\n\n\nS002\n2022\n78\n\n\nS002\n2023\n81\n\n\nS002\n2024\n85\n\n\nS003\n2022\n92\n\n\nS003\n2023\n95\n\n\nS003\n2024\n98"
  },
  {
    "objectID": "lectures/lecture_1.html#data-structure-tidy-data-3",
    "href": "lectures/lecture_1.html#data-structure-tidy-data-3",
    "title": "From Messy Data to Research Insights",
    "section": "Data Structure & Tidy Data",
    "text": "Data Structure & Tidy Data\n(Typical) Finance data structures\n\nCross-sectional: One observation per firm (snapshot)\nTime series: Multiple observations over time for one firm\nPanel data: Multiple firms √ó multiple time periods ‚Üí firm-year observations\n\n\nMost of your thesis work will use panel data. We‚Äôll return to this in Lecture 4"
  },
  {
    "objectID": "lectures/lecture_1.html#data-structure-tidy-data-4",
    "href": "lectures/lecture_1.html#data-structure-tidy-data-4",
    "title": "From Messy Data to Research Insights",
    "section": "Data Structure & Tidy Data",
    "text": "Data Structure & Tidy Data\nWhat else is there?\n\n\nOther data structures\n\nHierarchical / nested data\n\nXBRL data\nJSON data\nLists in R/Python\nDictionaries in Python\n\nSpatial data\n\nShapefiles, GeoJSON\nGIS software (ArcGIS, QGIS)\n\n\n\nDatabase types\n\nRelational databases\n\nSQL databases, e.g.¬†PostgreSQL (WRDS), MySQL (backend of many web apps)\nNoSQL databases, e.g.¬†MongoDB (document storage)\n\nTime-series databases\n\nInfluxDB, TimescaleDB\n\n\n\n\nThese are beyond the scope of this course!"
  },
  {
    "objectID": "lectures/lecture_1.html#data-structure-tidy-data-5",
    "href": "lectures/lecture_1.html#data-structure-tidy-data-5",
    "title": "From Messy Data to Research Insights",
    "section": "Data Structure & Tidy Data",
    "text": "Data Structure & Tidy Data\nEach on teach one: Where to get finance data?\nKey data sources\n\n\nWRDS (Wharton Research Data Services)\n\nPrices: CRSP (US), Compustat Global, and Datastream/LSEG (global)\nIntraday prices: TAQ\nListed firms‚Äô fundamentals: CRSP, Compustat, Bureau van Dijk\nPrivate firms: Bureau van Dijk (Orbis, Amadeus)\nInstitutional ownership: Thomson Reuters Institutional (13F) Holdings\nBoard and Executives: BoardEx, ExecuComp, Incentive Lab\nAnalyst forecasts: I/B/E/S\nAuditor data: Audit Analytics\n10-K/SEC filings: EDGAR\nESG data: MSCI ESG, Sustainalytics\n\n\nLibrary & other sources\n\nMutual funds, ETFs, etc.: Morningstar Direct: Mutual funds, ETFs, etc.\nMergers & Acquisitions: SDC Platinum\nText data:\n\nREddit (via API)\nSEC filings (via EDGAR or WRDS)\nNews data (via Bloomberg, Refinitiv, or other providers)\n\nMacroeconomic data: FRED, World Bank, IMF, OECD"
  },
  {
    "objectID": "lectures/lecture_1.html#data-structure-tidy-data-6",
    "href": "lectures/lecture_1.html#data-structure-tidy-data-6",
    "title": "From Messy Data to Research Insights",
    "section": "Data Structure & Tidy Data",
    "text": "Data Structure & Tidy Data\nEach on teach one: How to access Data?\nAccess via Library\n\nOn-campus access: Direct access via IP recognition\nOff-campus access: Remote desktop via RSM VPN\nSee Erasmus Data Service Centre (EDSC)\n\nAccessing WRDS\n\n\nWRDS via web interface\n\nPoint-and-click data extraction\nExport to CSV, Stata, SAS, R, Python\nGood for one-off downloads\n\n\nWRDS via API\n\nProgrammatic access via Python, R, Stata (and SAS)\nGood for reproducible research workflows\nSee WRDS documentation for details\n\n\n\n\nThe course assignments will provide data files directly, so you don‚Äôt need to set up WRDS access for this course."
  },
  {
    "objectID": "lectures/lecture_1.html#merging-identifiers-1",
    "href": "lectures/lecture_1.html#merging-identifiers-1",
    "title": "From Messy Data to Research Insights",
    "section": "Merging & Identifiers",
    "text": "Merging & Identifiers\nWhy do we care?\n\nReal-world data is messy and fragmented\nDifferent databases use different identifiers\nMerging datasets is essential for comprehensive analysis\nUnderstanding identifiers helps avoid merge errors and data inconsistencies\n\n\nMost important step to get from raw data to analysis-ready data!"
  },
  {
    "objectID": "lectures/lecture_1.html#merging-identifiers-2",
    "href": "lectures/lecture_1.html#merging-identifiers-2",
    "title": "From Messy Data to Research Insights",
    "section": "Merging & Identifiers",
    "text": "Merging & Identifiers\nThe Identifier Zoo\n\n\n\nCommon Identifiers Across Major Finance Databases\n\n\nSource\nCRSP\nCompustat\nThomson Refinitiv\n\n\n\n\nCRSP\nLinking within the CRSP Environment\nCRSP/Compustat Merged (CCM)\nMFLINKs for Mutual Fund Linking; Linking through CUSIP; 13F Linking Program\n\n\nCompustat\nCRSP/Compustat Merged (CCM); Using Compustat Historical Identifiers\nLinking within the Compustat Environment using GVKEY\nLink through CUSIP\n\n\nCapital IQ\nCIQ company ID linked to GVKEY and then to CRSP\nLinking within Capital IQ\nLink through CUSIP, ISIN or Ticker\n\n\nIBES\nIBES CRSP Link\nLink through CRSP\nLink through Security Mapping\n\n\nAudit Analytics\nLink through Compustat\nLink through CIK Link (primary); Link through Ticker (secondary)\nLink these two products using Compustat\n\n\nBoardEx\nLink with CRSP and Compustat\nLink with CRSP and Compustat\nTR Insiders Boardex Link\n\n\nBond: TRACE / Mergent FISD\nBond CRSP Link\nLink through CRSP\nLink through CRSP\n\n\nBureau van Dijk\nLink through ISIN (CUSIP) for US Companies\nLink through CRSP\nLink through ISIN or SEDOL\n\n\n\n\n\nSource: WRDS Linking Matrix"
  },
  {
    "objectID": "lectures/lecture_1.html#merging-identifiers-3",
    "href": "lectures/lecture_1.html#merging-identifiers-3",
    "title": "From Messy Data to Research Insights",
    "section": "Merging & Identifiers",
    "text": "Merging & Identifiers\nThe Identifier Zoo\nWhy so many?\n\nDifferent databases, different purposes, historical reasons\nCRSP uses PERMNO, Compustat uses GVKEY, SEC filings use CIK, everyone uses CUSIP (but which version?)\n\n\n\n\n\nIdentifier\nSource1\nWhat it identifies\nPersistence\n\n\n\n\nCUSIP\nCompustat\nSecurity\nCan change!\n\n\nGVKEY\nCompustat\nCompany\nStable\n\n\nPERMNO\nCRSP\nSecurity\nStable\n\n\nISIN\nRefinitiv\nSecurity\nCan change!\n\n\nTICKER\nRefinitiv\nSecurity\nCan change!\n\n\n\n\nIdentifiers may be available in multiple databases; source indicates common origin."
  },
  {
    "objectID": "lectures/lecture_1.html#merging-identifiers-4",
    "href": "lectures/lecture_1.html#merging-identifiers-4",
    "title": "From Messy Data to Research Insights",
    "section": "Merging & Identifiers",
    "text": "Merging & Identifiers\nThe Identifier Zoo\nWhy so many?\n\nDifferent databases, different purposes, historical reasons\nCRSP uses PERMNO, Compustat uses GVKEY, SEC filings use CIK, everyone uses CUSIP (but which version?)\n\n\n\n\n\n\n\nKey insights\n\n\n\nAlways check which identifier(s) your datasets use before merging!\nCheck WRDS to find linking tables between identifiers (e.g., CRSP-Compustat link)\nSaves a ton of work and headache later!"
  },
  {
    "objectID": "lectures/lecture_1.html#merging-identifiers-5",
    "href": "lectures/lecture_1.html#merging-identifiers-5",
    "title": "From Messy Data to Research Insights",
    "section": "Merging & Identifiers",
    "text": "Merging & Identifiers\nMerge Types\nFundamentals\n\n\n1:1 Merge (a.k.a. inner-join)\n\n\nWhat to watch out for?\n\nEnsure both datasets have unique keys\nCheck for unexpected duplicates before merging\nNon-matches: Decide how to handle them (drop)"
  },
  {
    "objectID": "lectures/lecture_1.html#merging-identifiers-6",
    "href": "lectures/lecture_1.html#merging-identifiers-6",
    "title": "From Messy Data to Research Insights",
    "section": "Merging & Identifiers",
    "text": "Merging & Identifiers\nMerge Types\nFundamentals\n\n\n1:m Merge (a.k.a. left-join)\n\n\nm:1 Merge (a.k.a. right-join)\n\n\nWhat to watch out for?\n\nEnsure both datasets have unique keys\nCheck for unexpected duplicates before merging\nUnderstand the direction of the merge (which dataset is ‚Äúmaster‚Äù)\nDecide how to handle non-matches (keep/drop)\n\nKeep all from ‚Äúmaster‚Äù dataset"
  },
  {
    "objectID": "lectures/lecture_1.html#merging-identifiers-7",
    "href": "lectures/lecture_1.html#merging-identifiers-7",
    "title": "From Messy Data to Research Insights",
    "section": "Merging & Identifiers",
    "text": "Merging & Identifiers\nMerge Types\nFundamentals\n\n\nm:m Merge\n\n\nWhat to watch out for?\n\nAvoid m:m merges whenever possible!\nUsually indicates a problem with the data or merge keys\nCan lead to data explosion and incorrect results\nIf unavoidable, carefully check the results and understand implications"
  },
  {
    "objectID": "lectures/lecture_1.html#merging-identifiers-8",
    "href": "lectures/lecture_1.html#merging-identifiers-8",
    "title": "From Messy Data to Research Insights",
    "section": "Merging & Identifiers",
    "text": "Merging & Identifiers\nExample"
  },
  {
    "objectID": "lectures/lecture_1.html#merging-identifiers-9",
    "href": "lectures/lecture_1.html#merging-identifiers-9",
    "title": "From Messy Data to Research Insights",
    "section": "Merging & Identifiers",
    "text": "Merging & Identifiers\nExample"
  },
  {
    "objectID": "lectures/lecture_1.html#merging-identifiers-10",
    "href": "lectures/lecture_1.html#merging-identifiers-10",
    "title": "From Messy Data to Research Insights",
    "section": "Merging & Identifiers",
    "text": "Merging & Identifiers\nReality check\nBest practices for merging data\n\nCheck uniqueness before merging\nCheck match rates after merging\nInvestigate unmatched observations‚Äîare they expected?\n\nExamples\n\nMerging firm fundamentals (Compustat) with stock prices (CRSP)\n\nUse CRSP-Compustat link table (gvkey ‚ÜîÔ∏é permno)\n\nOr download the merged dataset directly from WRDS!üòâ\n\nOne gvkey (Compustat) per firm to multiple daily prices (1:m) per year\nLeft-join: Keep all firm-(years) from Compustat, add prices from CRSP"
  },
  {
    "objectID": "lectures/lecture_1.html#vw-dieselgate",
    "href": "lectures/lecture_1.html#vw-dieselgate",
    "title": "From Messy Data to Research Insights",
    "section": "VW Dieselgate",
    "text": "VW Dieselgate\nWhat happened?\n\n\nStill making headlines today\n\n\n\nFT (2025)\n\n\n\nSeptember 2015\nSeptember 3\nVW engineers privately admitted to the US Environmental Protection Agency that 480,000 diesel cars had been fitted with illegal defeat devices to understate emissions\nSeptember 18\nEPA publicly announced it had found software-based defeat devices on model year 2009-2015 VW and Audi diesel cars with 2-litre engines\nSeptember 23\nMartin Winterkorn resigned as CEO, stating ‚ÄúI am not aware of any wrongdoing on my part‚Äù\nAsk FT (2026)"
  },
  {
    "objectID": "lectures/lecture_1.html#vw-dieselgate-1",
    "href": "lectures/lecture_1.html#vw-dieselgate-1",
    "title": "From Messy Data to Research Insights",
    "section": "VW Dieselgate",
    "text": "VW Dieselgate\nThe timeline\n\n\n\nSee also FT (2015)"
  },
  {
    "objectID": "lectures/lecture_1.html#vw-dieselgate-2",
    "href": "lectures/lecture_1.html#vw-dieselgate-2",
    "title": "From Messy Data to Research Insights",
    "section": "VW Dieselgate",
    "text": "VW Dieselgate\nWhy this matters for finance research and pratice\n\n\nResearch implications/opportunities\n\nEvent study opportunity (Lecture 5 preview)\nCross-firm contagion (did other automakers suffer?)\nData challenges: Matching news to stock prices, firms to industries, prices to accounting data\n\n\nPractical implications\n\nRisk management: How to price in such events?\nRegulatory oversight: Detecting fraud early\nCorporate governance: Preventing future scandals\nLegal consequences: Class-action lawsuits, fines"
  },
  {
    "objectID": "lectures/lecture_1.html#vw-dieselgate-3",
    "href": "lectures/lecture_1.html#vw-dieselgate-3",
    "title": "From Messy Data to Research Insights",
    "section": "VW Dieselgate",
    "text": "VW Dieselgate\nWhat does it have to do with the assignments?\nAssignments 1-5 use VW Dieselgate as a running example‚Ä¶\n\nAssignment 1: Data wrangling & visualization\nAssignment 2: visualization\nAssignment 3: Cross-sectional regression analysis (OLS)\nAssignment 4: Panel data regression analysis (DiD)\nAssignment 5: Event study analysis"
  },
  {
    "objectID": "lectures/lecture_1.html#vw-dieselgate-4",
    "href": "lectures/lecture_1.html#vw-dieselgate-4",
    "title": "From Messy Data to Research Insights",
    "section": "VW Dieselgate",
    "text": "VW Dieselgate\nAssignment 1 walkthrough\nThe skinny\n\n\nData\n\nWRDS Compustat + CRSP\nauto_firms_raw.csv: Company identifiers and industry codes from Compustat\nauto_firms_prices.csv: Daily stock prices for automakers\nAll data provided in the assignment folder on JupyterHub\n\n\nYour tasks\n\nClean the header file (filter to relevant firms‚ÄîGerman automakers including VW)\nMerge price data to get one analysis-ready ‚Äútidy‚Äù dataset\nCreate basic variables (returns, log prices) and publication-quality tables\nTeaser lecture 2: Time-series plot of VW‚Äôs stock price with event annotation\n\n\n\nAll details in the assignment document."
  },
  {
    "objectID": "lectures/lecture_1.html#references",
    "href": "lectures/lecture_1.html#references",
    "title": "From Messy Data to Research Insights",
    "section": "References",
    "text": "References\n\n\nHuntington-Klein, Nick. 2022. The Effect: An Introduction to Research Design and Causality. 2nd ed. Chapman; Hall/CRC.\n\n\nVerbeek, Marno. 2021. Panel Methods for Finance: A Guide to Panel Data Econometrics for Financial Applications. De Gruyter."
  },
  {
    "objectID": "lectures/lecture_1.html#appendix-1",
    "href": "lectures/lecture_1.html#appendix-1",
    "title": "From Messy Data to Research Insights",
    "section": "Appendix",
    "text": "Appendix\nWrds Web Interface example\nAccessing WRDS via web interface - Compustat"
  },
  {
    "objectID": "lectures/lecture_3.html#regressions-and-identification-1",
    "href": "lectures/lecture_3.html#regressions-and-identification-1",
    "title": "Regressions and Identification",
    "section": "Regressions and Identification",
    "text": "Regressions and Identification\nToday‚Äôs Journey\n\nIdentification: What it means and why it matters\nThe identification problem: Endogeneity\n\nSelection bias\nOmitted variable bias\n\nDiLLMa: seeing the problem in action\nThe gold standard: Experiments\nOrdinary Least Squares (OLS) regression\n\nLiterature\n\nHuntington-Klein (2022) (Chapters 5 & 13)\nVerbeek (2021) (Chapters 2.1)"
  },
  {
    "objectID": "lectures/lecture_3.html#regressions-and-identification-2",
    "href": "lectures/lecture_3.html#regressions-and-identification-2",
    "title": "Regressions and Identification",
    "section": "Regressions and Identification",
    "text": "Regressions and Identification\nRecap - Where did we leave things?\n\n\nLast time: The Research Pipeline\n\n\nRaw & Clean Data, Visualization\n\nFrom messy to tidy data\nExploratory data analysis with focus on visualization\n\nToday‚Äôs Menu\n\nIdentification & OLS regression\nExperiments\nDiLLMa (example)"
  },
  {
    "objectID": "lectures/lecture_3.html#regressions-and-identification-3",
    "href": "lectures/lecture_3.html#regressions-and-identification-3",
    "title": "Regressions and Identification",
    "section": "Regressions and Identification",
    "text": "Regressions and Identification\nLearning Objectives\nBy the end of today, you will be able to\n\nUnderstand the concept of identification in causal inference\nRecognize endogeneity issues such as selection bias and omitted variable bias\nExplain the importance of random assignment in experiments\nDescribe the basics of Ordinary Least Squares (OLS) regression\nInterpret OLS regression output and understand when estimates are trustworthy\n\n\n\n\n\n\n\nHands-on Practice\n\n\nIn Assignment 3, you‚Äôll apply these concepts: run OLS regressions, test assumptions, and create publication-quality tables."
  },
  {
    "objectID": "lectures/lecture_3.html#regressions-and-identification-4",
    "href": "lectures/lecture_3.html#regressions-and-identification-4",
    "title": "Regressions and Identification",
    "section": "Regressions and Identification",
    "text": "Regressions and Identification\nIntroduction to Identification\nKey concepts\n\n\n\n\n\n\n\n\n\nConcept\nMeaning\nExample\n\n\n\n\nData‚ÄëGenerating Process (DGP)\nThe complete set of rules that determine how the data you observe are created\nNewton‚Äôs law of gravity\n\n\nVariation\nThe differences in a variable‚Äôs value across observations.\nHow people‚Äôs incomes differ by hair color across individuals.\n\n\nIdentification\nThe process of ensuring that the variation you exploit is causal, not a spurious alternative\nChocolate consumption and Nobel laureates (this is spurious)"
  },
  {
    "objectID": "lectures/lecture_3.html#identification",
    "href": "lectures/lecture_3.html#identification",
    "title": "Regressions and Identification",
    "section": "Identification",
    "text": "Identification\nWhy is identification important?\nIdentification is the bridge between:\n\nTheory / prior knowledge (what we already know about the DGP)\nData (what we observe)\nCausal or associational conclusions that are scientifically defensible"
  },
  {
    "objectID": "lectures/lecture_3.html#identification-1",
    "href": "lectures/lecture_3.html#identification-1",
    "title": "Regressions and Identification",
    "section": "Identification",
    "text": "Identification\nWhat is identification?\nDefinition\n\nIdentification refers to the process of determining the specific variation in data that answers a research question\nIt involves isolating the part of the data that reflects the causal relationship of interest\n\nExample\n\nEstimating the effect of LLM use on exam scores1\nNeed to isolate variation in LLM use that is not confounded by other factors (e.g., student ability)\n\nFor an alternative example see Huntington-Klein (2022) (Chapter 5)"
  },
  {
    "objectID": "lectures/lecture_3.html#identification-2",
    "href": "lectures/lecture_3.html#identification-2",
    "title": "Regressions and Identification",
    "section": "Identification",
    "text": "Identification\nWhat are the ingredients for identification?\nKey Assumptions\nData Generating Process (DGP)\nAssumes that observations are produced by underlying laws or processes\nTheory and Assumptions\nUsed to identify which parts of the DGP explain the data and refine research designs\nLimiting Explanation\nAssumptions help block non-essential variations, focusing on the aspect of data that aligns with the research question."
  },
  {
    "objectID": "lectures/lecture_3.html#identification-3",
    "href": "lectures/lecture_3.html#identification-3",
    "title": "Regressions and Identification",
    "section": "Identification",
    "text": "Identification\nKey Assumptions in DGP and Identification\nKnown & Unknown\nPart of DGP is understood (helps form assumptions); part is unknown (area of exploration)\nTheoretical Framework\nResearch relies on known aspects of DGP to interpret data and identify genuine causal effects\nIdentification Strategy\nTechniques like controlling for variables, subgroup analyses, or hypothetical scenarios help test specific segments of DGP\nAssumption-Based Progress\nContinued research and empirical testing refine and validate assumptions about parts of the DGP"
  },
  {
    "objectID": "lectures/lecture_3.html#endogeneity",
    "href": "lectures/lecture_3.html#endogeneity",
    "title": "Regressions and Identification",
    "section": "Endogeneity",
    "text": "Endogeneity\nWhat can go wrong?\nWhen we try to estimate causal effects, we face a fundamental challenge:\n\nEndogeneity occurs when the explanatory variable (X) is correlated with the error term (Œµ) in our model.\n\nThis correlation can arise from several sources‚Ä¶ let‚Äôs focus on two of the most common1\n\n\nMathematically: \\(\\text{Cov}(X, \\varepsilon) \\neq 0\\)\nOther sources include measurement error and simultaneity (X causes Y and Y causes X -&gt; Think: Police and Crime rates)."
  },
  {
    "objectID": "lectures/lecture_3.html#endogeneity-1",
    "href": "lectures/lecture_3.html#endogeneity-1",
    "title": "Regressions and Identification",
    "section": "Endogeneity",
    "text": "Endogeneity\nSource 1: Selection Bias\nDefinition\nSelection bias occurs when individuals [self-select[ into treatment based on characteristics that also affect the outcome.\nThe problem\n\nPeople who choose to do X are [systematically different[ from those who don‚Äôt\nThese differences‚Äînot X itself‚Äîmay explain the outcome\n\nClassic examples\n\nDo hospitals make people healthier? (Sick people go to hospitals)\nDoes college increase earnings? (High-ability students attend college)\nDo LLMs improve exam scores? (Tech-savvy students use LLMs)"
  },
  {
    "objectID": "lectures/lecture_3.html#endogeneity-2",
    "href": "lectures/lecture_3.html#endogeneity-2",
    "title": "Regressions and Identification",
    "section": "Endogeneity",
    "text": "Endogeneity\nSource 2: Omitted Variable Bias (OVB)\nDefinition\nOmitted variable bias occurs when a relevant variable that affects both the explanatory variable (X) and the outcome (Y) is left out of the analysis.\n\n\nThe problem\n\nThe omitted variable ‚Äúconfounds‚Äù the relationship\nWe attribute its effect to X, biasing our estimate\n\n\nFormal condition for OVB\nA variable Z causes OVB if:\n\nZ affects Y (Z ‚Üí Y)\nZ is correlated with X (Z ‚ÜîÔ∏é X)\nZ is not included in the model\n\n\n\n\n\n\n\n\nThe connection\n\n\nSelection bias is one cause of OVB. When people self-select based on characteristic Z (which also affects Y), and we omit Z from our model, we have OVB."
  },
  {
    "objectID": "lectures/lecture_3.html#endogeneity-3",
    "href": "lectures/lecture_3.html#endogeneity-3",
    "title": "Regressions and Identification",
    "section": "Endogeneity",
    "text": "Endogeneity\nVisualizing the Problem\n\n\n\n\n\n\n\nKey insight\n\n\nIf ability affects both LLM use and exam scores, any naive comparison of LLM users vs.¬†non-users will be confounded."
  },
  {
    "objectID": "lectures/lecture_3.html#endogeneity-4",
    "href": "lectures/lecture_3.html#endogeneity-4",
    "title": "Regressions and Identification",
    "section": "Endogeneity",
    "text": "Endogeneity\nWhy does this matter?\nThe consequence\nEndogeneity can:\n\nInflate the estimated effect (make X look better than it is)\nDeflate the estimated effect (make X look worse than it is)\nFlip the sign of the estimated effect (make X look beneficial when it‚Äôs harmful, or vice versa)\n\nThe challenge\nWe often cannot directly observe the confounding variables!\n\nLet‚Äôs see this problem in action with a concrete example‚Ä¶"
  },
  {
    "objectID": "lectures/lecture_3.html#dillma",
    "href": "lectures/lecture_3.html#dillma",
    "title": "Regressions and Identification",
    "section": "‚ÄúDiLLMa‚Äù",
    "text": "‚ÄúDiLLMa‚Äù\nWhat‚Äôs the story?\n\n\nMotivation\n\nLLMs are increasingly used by students e.g.¬†for exam preparation\nThere is a debate about whether LLM use improves or hinders learning outcomes\nUnderstanding the causal effect of LLM use on exam scores is crucial for educators and policymakers\n\n\nIdentification challenge\n\nWe have observational data on students‚Äô LLM use and their exam scores\nWe need to identify the causal effect of LLM use on exam scores, accounting for potential confounders like student ability, study habits, and demographics\n\n\n\n\n\n\n\n\nResearch question\n\n\nWhat is the effect of LLM use on students‚Äô exam scores?\n\n\n\nLibby Boxes"
  },
  {
    "objectID": "lectures/lecture_3.html#identification-4",
    "href": "lectures/lecture_3.html#identification-4",
    "title": "Regressions and Identification",
    "section": "Identification",
    "text": "Identification\nWhat could possibly go wrong?\n\n\nNaive comparison\n\n\n\n\n\n\n\n\n\n\nWhat do we find?\n\nStudents who used LLMs scored higher on average\nNaive comparison suggests a positive effect of LLM use on exam scores\nEconomic effect: ~0.5 point increase in exam scores\n\n\n\n\n\n\n\n\nBut‚Ä¶\n\n\nIs this effect causal? Or are there confounding factors at play?"
  },
  {
    "objectID": "lectures/lecture_3.html#dillma-1",
    "href": "lectures/lecture_3.html#dillma-1",
    "title": "Regressions and Identification",
    "section": "DiLLMa",
    "text": "DiLLMa\nStep 2: Looking at Observable Characteristics\n\n\nVariables in the dataset\n\n\n\n\n\n\nVariable\nLLM\nNo LLM\nDifference\nt-stat.\np-value\n\n\n\n\nExam score\n7.04\n6.55\n0.50\n-5.99\n0.00\n\n\nAttendance rate\n74.15\n75.43\n-1.28\n1.42\n0.15\n\n\nFemale\n0.49\n0.50\n-0.01\n0.39\n0.70\n\n\nAge\n21.37\n21.34\n0.03\n-0.18\n0.86\n\n\nStudy hours\n20.09\n20.34\n-0.25\n0.35\n0.73\n\n\n\n\n\n\n\n‚ÄúEye test‚Äù\n\nThe LLM group has a higher average exam scores\nThe groups are comparable on observable characteristics, on average1\nHowever, there may be unobservable factors (e.g., innate ability, motivation) that differ between the groups and affect exam scores\n\n\nThe gender variable is coded as 1 if the subject identifies as female, and 0 otherwise."
  },
  {
    "objectID": "lectures/lecture_3.html#think-about-it-for-a-moment",
    "href": "lectures/lecture_3.html#think-about-it-for-a-moment",
    "title": "Regressions and Identification",
    "section": "Think about it for a moment‚Ä¶",
    "text": "Think about it for a moment‚Ä¶"
  },
  {
    "objectID": "lectures/lecture_3.html#dillma-2",
    "href": "lectures/lecture_3.html#dillma-2",
    "title": "Regressions and Identification",
    "section": "DiLLMa",
    "text": "DiLLMa\nStep 3: What about ability?\n\nWhat happens if we could observe and condition on (or control for) ability?\n\n\nNow, it comes in handy that I created the data myself and we can actually observe ability!"
  },
  {
    "objectID": "lectures/lecture_3.html#dillma-3",
    "href": "lectures/lecture_3.html#dillma-3",
    "title": "Regressions and Identification",
    "section": "DiLLMa",
    "text": "DiLLMa\nStep 4: The Reveal\n\n\nControlling for ability1\n\n\n\n\n\n\n\n\n\n\nWhat do we find?\n\nStudents who used LLMs scored lower on average\nNaive comparison suggested a positive effect ‚Üí now it‚Äôs negative\nEconomic effect: ~0.5 point decrease in exam scores\n\n\nAbility is typically unobservable in real-world settings, making it a classic example of an omitted variable."
  },
  {
    "objectID": "lectures/lecture_3.html#do-unobservable-factors-play-a-role",
    "href": "lectures/lecture_3.html#do-unobservable-factors-play-a-role",
    "title": "Regressions and Identification",
    "section": "Do unobservable factors play a role?",
    "text": "Do unobservable factors play a role?\nLet‚Äôs dissect the results\n\n\nConditional means: -0.31 to -0.26\n\n\n\n\n\n\nGroup\nLLM\nNo LLM\nDifference\n\n\n\n\nLow ability\n5.83\n6.13\n-0.31\n\n\nHigh ability\n7.45\n7.72\n-0.26\n\n\n\n\n\n\n\nGroup composition\n\n\n\n\n\n\nGroup\nLLM\nNo LLM\nDifference\n\n\n\n\nLow ability\n122\n379\n-257\n\n\nHigh ability\n364\n135\n229\n\n\n\n\n\n\n\n\n\n\n\n\n\nKey insight\n\n\n\nWithin high-ability students: LLM users do worse\nWithin low-ability students: LLM users do worse"
  },
  {
    "objectID": "lectures/lecture_3.html#do-unobservable-factors-play-a-role-1",
    "href": "lectures/lecture_3.html#do-unobservable-factors-play-a-role-1",
    "title": "Regressions and Identification",
    "section": "Do unobservable factors play a role?",
    "text": "Do unobservable factors play a role?\nLet‚Äôs dissect the results\nUnconditional means\n\\[\n\\text{LLM users: }\\frac{122 \\times 5.83 + 364 \\times 7.45}{486} \\approx 7.04\n\\] \\[\n\\text{Non-users: }\\frac{379 \\times 6.13 + 135 \\times 7.72}{514} \\approx 6.55\n\\]\nNaive effect: +0.49 (positive!)\n\nLLMs hurt everyone ‚Äî we were just fooled by who chose to use them."
  },
  {
    "objectID": "lectures/lecture_3.html#what-did-we-just-discover-1",
    "href": "lectures/lecture_3.html#what-did-we-just-discover-1",
    "title": "Regressions and Identification",
    "section": "What did we just discover?",
    "text": "What did we just discover?\nRecap of findings\n\n\nResults summary\n\nNaive test: positive effect ‚Üí ‚ÄúLLMs improve grades!‚Äù\nAdd ability control: effect flips negative ‚Üí ‚ÄúWait, no they don‚Äôt‚Äù\nConditional means plot: the reveal‚ÄîLLMs hurt everyone, we were just fooled by who chooses to use them\n\n\nKey insight\n\n\n\n\n\n\nThis is Selection Bias\n\n\nThe groups differed systematically on ability. High-ability students selected into LLM use ‚Äî and they would have done well anyway."
  },
  {
    "objectID": "lectures/lecture_3.html#dillma-4",
    "href": "lectures/lecture_3.html#dillma-4",
    "title": "Regressions and Identification",
    "section": "DiLLMa",
    "text": "DiLLMa\nWhat we just witnessed\n\n\nThe pattern\n\n\n\n\n\n\n\n\n\nAnalysis\nLLM Coefficient\nInterpretation\n\n\n\n\nNaive comparison\nPositive\nLLMs help!\n\n\nControl for ability\nNegative\nLLMs hurt!\n\n\n\n\n\nThe explanation\nThis is a textbook case of selection bias manifesting as omitted variable bias:\n\nSelection bias: High-ability students self-select into LLM use\nOVB: When ability is omitted, its effect is attributed to LLM use\nResult: The naive estimate is biased upward\n\n\n\n\n\n\n\n\nKey takeaway\n\n\nNaive comparisons can be misleading due to endogeneity issues like selection bias and OVB!"
  },
  {
    "objectID": "lectures/lecture_3.html#dillma-5",
    "href": "lectures/lecture_3.html#dillma-5",
    "title": "Regressions and Identification",
    "section": "DiLLMa",
    "text": "DiLLMa\nThe Sign-Flip Phenomenon\n\n\n\n\n\n\nCritical insight\n\n\nOmitted variable bias doesn‚Äôt just make estimates imprecise‚Äîit can completely flip the sign of your estimate!\n\n\n\nIn our example:\n\nTrue effect of LLM use: Negative (LLMs hurt learning)\nNaive estimate: Positive (because high-ability students use LLMs)\nBias: Positive (ability is positively correlated with both LLM use and exam scores)\n\nThe formula (intuition):\n\\[\\text{Naive estimate} = \\text{True effect} + \\text{Bias}\\] \\[\\text{Positive} = \\text{Negative} + \\text{(Large) Positive}\\]"
  },
  {
    "objectID": "lectures/lecture_3.html#the-gold-standard-experiments",
    "href": "lectures/lecture_3.html#the-gold-standard-experiments",
    "title": "Regressions and Identification",
    "section": "The gold standard: Experiments",
    "text": "The gold standard: Experiments\nWhy is randomization so important?\n\nControlling variation in the causal variable, e.g.¬†LLM use via random assignment\nMakes sure that the treatment and control group are similar along observable and unobservable dimensions\nThe only difference between the two groups is the treatment\nThis allows us to attribute any difference in outcomes to the treatment\nNo selection bias (endogeneity issue)\n\n\n\nAnother term for Experiments is Randomized Controlled Trials (RCTs)."
  },
  {
    "objectID": "lectures/lecture_3.html#the-gold-standard-experiments-1",
    "href": "lectures/lecture_3.html#the-gold-standard-experiments-1",
    "title": "Regressions and Identification",
    "section": "The gold standard: Experiments",
    "text": "The gold standard: Experiments\nDesigning and analyzing experiments\nTypes of experiments:\n\nField experiments\n\naim to be as similar as possible to real-world decision situations\n\nA/B testing\n\naim to evaluate different versions of the same product\n\nLab experiments\n\nare carried out in an artificial environment, usually a computer lab\n\n\n\n\nFor more in-depth information on experiments and other causal inference methods, see B√©k√©s and K√©zdi (2021)."
  },
  {
    "objectID": "lectures/lecture_3.html#the-gold-standard-experiments-2",
    "href": "lectures/lecture_3.html#the-gold-standard-experiments-2",
    "title": "Regressions and Identification",
    "section": "The gold standard: Experiments",
    "text": "The gold standard: Experiments\nSetup of an experiment\n\nRandom assignment of treatment via assignment rule\nNumber of subjects? Ideally large, exact number via power analysis\n\nHow many subjects do I need to detect a certain effect size?\n\nProportion of treated subjects? Ideally 50/50\nCovariate balance\n\nDid random assignment work?"
  },
  {
    "objectID": "lectures/lecture_3.html#the-gold-standard-experiments-3",
    "href": "lectures/lecture_3.html#the-gold-standard-experiments-3",
    "title": "Regressions and Identification",
    "section": "The gold standard: Experiments",
    "text": "The gold standard: Experiments\nDiLLMa experiment\n\nRandomly assign students to LLM use or no LLM use\nEnsure groups are balanced on observable characteristics (e.g., prior GPA, study habits)\nMeasure exam scores after the treatment period\nAnalyze the difference in exam scores between the treatment and control groups"
  },
  {
    "objectID": "lectures/lecture_3.html#the-gold-standard-experiments-4",
    "href": "lectures/lecture_3.html#the-gold-standard-experiments-4",
    "title": "Regressions and Identification",
    "section": "The gold standard: Experiments",
    "text": "The gold standard: Experiments\nDiLLMa experiment\nRandom assignment of LLM use\n\n\nNaive comparison\n\n\n\n\n\n\n\n\n\n\nWhat do we find?\n\nStudents who used LLMs scored lower on average\nNaive comparison suggests a negative effect of LLM use on exam scores\nEconomic effect: ~0.5 point decrease in exam scores\n\n\n\n\n\n\n\n\nBut‚Ä¶\n\n\nDid random assignment work? Are the groups balanced on observable & unobservable characteristics?"
  },
  {
    "objectID": "lectures/lecture_3.html#the-gold-standard-experiments-5",
    "href": "lectures/lecture_3.html#the-gold-standard-experiments-5",
    "title": "Regressions and Identification",
    "section": "The gold standard: Experiments",
    "text": "The gold standard: Experiments\nDiLLMa experiment\nCovariate balance check\n\n\n\n\n\n\nVariable\nLLM\nNo LLM\nDifference\nt-stat.\np-value\n\n\n\n\nExam score\n6.43\n7.22\n-0.80\n8.75\n0.00\n\n\nAttendance rate\n74.62\n75.01\n-0.39\n0.43\n0.66\n\n\nFemale\n0.49\n0.49\n0.00\n-0.02\n0.98\n\n\nAge\n21.29\n21.43\n-0.13\n0.91\n0.36\n\n\nStudy hours\n19.92\n20.56\n-0.64\n0.89\n0.37\n\n\nAbility\n0.01\n0.03\n-0.02\n0.33\n0.74"
  },
  {
    "objectID": "lectures/lecture_3.html#the-gold-standard-experiments-6",
    "href": "lectures/lecture_3.html#the-gold-standard-experiments-6",
    "title": "Regressions and Identification",
    "section": "The gold standard: Experiments",
    "text": "The gold standard: Experiments\nTakeaways\n\nRandom assignment assures that effect is not due to selection bias\nIn the experiment you control‚Ä¶\n\nwho receives the treatment (the treatment group),‚Ä¶\nand who doesn‚Äôt (the control group)\n\nYou can control other aspects of the situation to avoid other confounders\nYou can measure the effect of the treatment on the outcome\nPotential trade-off between internal and external validity"
  },
  {
    "objectID": "lectures/lecture_3.html#what-to-do-if-controlling-random-assignment-is-not-possible-1",
    "href": "lectures/lecture_3.html#what-to-do-if-controlling-random-assignment-is-not-possible-1",
    "title": "Regressions and Identification",
    "section": "What to do if controlling random assignment is not possible?",
    "text": "What to do if controlling random assignment is not possible?\nReality check\n\n\nThe reality of finance research\n\nMost financial phenomena cannot be experimentally manipulated\nWe rely on observational data\nNeed tools to make the best of imperfect situations\n\n\nTwo approaches\nOLS with controls (today)\n\nAdd observable confounders as control variables\nLimited: can‚Äôt control for unobservables\n\nQuasi-experimental methods (Lecture 4)\n\nExploit natural variation\nDifference-in-Differences, etc."
  },
  {
    "objectID": "lectures/lecture_3.html#ordinary-least-squares-ols-1",
    "href": "lectures/lecture_3.html#ordinary-least-squares-ols-1",
    "title": "Regressions and Identification",
    "section": "Ordinary Least Squares (OLS)",
    "text": "Ordinary Least Squares (OLS)\nThe Skinny\nWhat is OLS regression?\n\nOLS is the workhorse of explanatory analytics\nIt lets us answer ‚ÄúWhat would happen to the expected value of \\(Y\\) if we changed \\(X\\) by one unit?‚Äù\n\nPrediction vs explanation\n\nPrediction: use \\(X\\) to forecast \\(Y\\)\nStatistical explanation: describe the relationship between them via a functional form such as \\[\nY = \\beta_0 + \\beta_1 X + \\varepsilon.\n\\]\nThe coefficient \\(\\beta_1\\) is the slope ‚Äî a one‚Äëunit change in \\(X\\) is associated with a \\(\\beta_1\\) change in \\(Y\\)."
  },
  {
    "objectID": "lectures/lecture_3.html#ordinary-least-squares-ols-2",
    "href": "lectures/lecture_3.html#ordinary-least-squares-ols-2",
    "title": "Regressions and Identification",
    "section": "Ordinary Least Squares (OLS)",
    "text": "Ordinary Least Squares (OLS)\nThe Skinny\nChoosing a shape for the relationship\nLinear: \\[\nY = \\beta_0 + \\beta_1 X.\n\\]\n‚ÄúLinear‚Äëin‚Äëparameters‚Äù (e.g., quadratic): \\[\nY = \\beta_0 + \\beta_1 X + \\beta_2 X^2.\n\\]\nAdded variables and control (multi‚Äëpredictor/multiviriate OLS)\n\\[\nY = \\beta_0 + \\beta_1 X + \\beta_2 Z + \\varepsilon,\n\\] the coefficient on \\(X\\) is estimated using only the variation in \\(X\\) that is left after regressing \\(Z\\) out of both \\(X\\) and \\(Y\\) ‚Äî that is, you ‚Äúcontrol for‚Äù \\(Z\\).\n\n\nThere are also non‚Äëlinear models: logit, probit, poisson, etc."
  },
  {
    "objectID": "lectures/lecture_3.html#ordinary-least-squares-ols-3",
    "href": "lectures/lecture_3.html#ordinary-least-squares-ols-3",
    "title": "Regressions and Identification",
    "section": "Ordinary Least Squares (OLS)",
    "text": "Ordinary Least Squares (OLS)\nThe Skinny\nWhen does it work perfectly (OLS Assumptions)?\n\n\n\n\n\n\n\n\n\nAssumption\nWhat it requires\nRole\n\n\n\n\nLinearity\n\\(E[Y \\mid X] = \\beta_0 + \\beta_1 X\\)\nCorrect specification of functional form\n\n\nExogeneity\n\\(E[\\varepsilon \\mid X] = 0\\)\nEnsures \\(\\hat{\\beta}\\) is unbiased and consistent\n\n\nHomoscedasticity\n\\(Var(\\varepsilon \\mid X) = \\sigma^2\\)\nStandard errors are efficient and unbiased\n\n\nIndependence\nObservations are i.i.d.\nStandard error formulas are valid\n\n\nNormality (small samples)\n\\(\\varepsilon \\sim N(0, \\sigma^2)\\)\nValidates t-tests and confidence intervals"
  },
  {
    "objectID": "lectures/lecture_3.html#ordinary-least-squares-ols-4",
    "href": "lectures/lecture_3.html#ordinary-least-squares-ols-4",
    "title": "Regressions and Identification",
    "section": "Ordinary Least Squares (OLS)",
    "text": "Ordinary Least Squares (OLS)\nThe Skinny - For those who prefer plain English\nWhen does it work perfectly (OLS Assumptions)?\n\n\n\n\n\n\n\n\nAssumption\nPlain English\n\n\n\n\nLinearity\nThe relationship between X and Y is a straight line\n\n\nExogeneity\nX is not correlated with anything else that affects Y\n\n\nHomoscedasticity\nThe spread of errors is the same across all values of X\n\n\nIndependence\nOne observation doesn‚Äôt influence another\n\n\nNormality (small samples)\nErrors follow a bell curve‚Äîonly matters for hypothesis testing with few observations"
  },
  {
    "objectID": "lectures/lecture_3.html#ordinary-least-squares-ols-5",
    "href": "lectures/lecture_3.html#ordinary-least-squares-ols-5",
    "title": "Regressions and Identification",
    "section": "Ordinary Least Squares (OLS)",
    "text": "Ordinary Least Squares (OLS)\nThe Skinny\nWhat if assumptions are violated?\n\n\n\n\n\n\n\n\n\nAssumption\nIf violated\nHow to check\n\n\n\n\nLinearity\nEstimates are biased; wrong model\nPlot residuals vs fitted values\n\n\nExogeneity\nEstimates are biased and inconsistent\nTheory and DAGs; no direct test\n\n\nHomoscedasticity\nStandard errors are wrong (often too small)\nPlot residuals vs fitted; Breusch-Pagan test\n\n\nIndependence\nStandard errors are wrong\nDurbin-Watson test; check data structure\n\n\nNormality\nt-tests and CIs invalid in small samples\nQ-Q plot of residuals"
  },
  {
    "objectID": "lectures/lecture_3.html#ordinary-least-squares-ols-6",
    "href": "lectures/lecture_3.html#ordinary-least-squares-ols-6",
    "title": "Regressions and Identification",
    "section": "Ordinary Least Squares (OLS)",
    "text": "Ordinary Least Squares (OLS)\nThe Skinny\nWhat else could go wrong?\n\n\n\n\n\n\n\n\n\nIssue\nIf present\nHow to check\n\n\n\n\nMulticollinearity\nEstimates unbiased but imprecise; unstable coefficients\nCorrelation matrix; VIF &gt; 10\n\n\nOutliers\nSingle observations can distort estimates\nSummary stats; plots\n\n\nMeasurement error in X 1\nCoefficient biased toward zero (attenuation bias)\nTheory; compare multiple measures if available\n\n\nSmall sample size\nEstimates imprecise; normality assumption matters more\nCheck n relative to number of predictors\n\n\nMissing data\nBias if not missing completely at random\nCheck patterns; compare complete vs incomplete cases\n\n\n\n\nMeasurement error in X becomes an edogeneity issue when correlated with \\(\\epsilon\\). Measurement error in Y increases variance but does not bias coefficients."
  },
  {
    "objectID": "lectures/lecture_3.html#ordinary-least-squares-ols-7",
    "href": "lectures/lecture_3.html#ordinary-least-squares-ols-7",
    "title": "Regressions and Identification",
    "section": "Ordinary Least Squares (OLS)",
    "text": "Ordinary Least Squares (OLS)\nWhat does it look like?\n\n\nPlot\n\n\n\n\n\n\n\n\n\n\nTable output"
  },
  {
    "objectID": "lectures/lecture_3.html#ordinary-least-squares-ols-8",
    "href": "lectures/lecture_3.html#ordinary-least-squares-ols-8",
    "title": "Regressions and Identification",
    "section": "Ordinary Least Squares (OLS)",
    "text": "Ordinary Least Squares (OLS)\nWhat does the output tell me?\n\n\n\n\n\n\n\n\n\nComponent\nMeaning\nTypical notation\n\n\n\n\nRows (Coefficient, Standard Error)\nEstimate of \\(\\beta_j\\) and its SE (or t‚Äëstat)\n-0.021 (0.004)\n\n\nSignificance stars\nIndicates p‚Äëvalue thresholds\n*** = p &lt; .01\n\n\n\\(R^2\\)\nProportion of variance in \\(Y\\) explained by the model\n0.065\n\n\nAdjusted \\(R^2\\)\nCorrects \\(R^2\\) for number of predictors\n0.065\n\n\nF‚Äëstatistic\nJoint test that all non‚Äëconstant coefficients equal zero\n35.016\n\n\nRMSE\nStandard deviation of residuals (or ‚Äúroot mean squared error‚Äù)\n1.307"
  },
  {
    "objectID": "lectures/lecture_3.html#ordinary-least-squares-ols-9",
    "href": "lectures/lecture_3.html#ordinary-least-squares-ols-9",
    "title": "Regressions and Identification",
    "section": "Ordinary Least Squares (OLS)",
    "text": "Ordinary Least Squares (OLS)\nHow to interpret the output?\n\n\nTable output\n\n\n\n\nInterpretation\nPrecision: Given SE=0.004, even small differences in coefficients are detectable\nSignificance: *** indicates the coefficient differs from zero at the 1% level\nModel fit: \\(R^2\\) of 0.065 tells us only ~ 3% of the variation in scores is captured by the predictors\nt-stat: The slope is about 5 standard errors away from zero (0.021/0.004 = 5), indicating strong evidence against the null hypothesis of no effect\n\n\n\n\n\n\nTypically, we focus on the coefficient estimates, their precision (SEs), and significance levels to interpret OLS results."
  },
  {
    "objectID": "lectures/lecture_3.html#ordinary-least-squares-ols-10",
    "href": "lectures/lecture_3.html#ordinary-least-squares-ols-10",
    "title": "Regressions and Identification",
    "section": "Ordinary Least Squares (OLS)",
    "text": "Ordinary Least Squares (OLS)\nTakeaways\n\nThe error term separates what is explained by the predictors from everything else\nExogeneity is the linchpin that turns OLS estimates into unbiased causal indicators\nSampling variability is quantified by standard errors, which underpin hypothesis tests, p‚Äëvalues, and confidence intervals\nRegression tables encapsulate all of this: coefficients, precision, significance, model‚Äëfit metrics"
  },
  {
    "objectID": "lectures/lecture_3.html#ols-dillma",
    "href": "lectures/lecture_3.html#ols-dillma",
    "title": "Regressions and Identification",
    "section": "OLS DiLLMa",
    "text": "OLS DiLLMa\nDiLLMa OLS results"
  },
  {
    "objectID": "lectures/lecture_3.html#ols-dillma-1",
    "href": "lectures/lecture_3.html#ols-dillma-1",
    "title": "Regressions and Identification",
    "section": "OLS DiLLMa",
    "text": "OLS DiLLMa\nDiLLMa OLS results\n\n\nPrior findings recap\n\n\n\n\n\n\nReconciling OLS with comparison of means\n\nThe coefficient on llm in the naive OLS regression is equivalent to the difference in means between LLM users and non-users\nAdding controls adjusts for confounding variables, changing the estimated effect of LLM use on exam scores\nIncluding ability further refines the estimate by accounting for this key confounder and gives us the ‚Äútrue‚Äù effect of LLM use\nRandom assignment eliminates confounding, so the naive estimate from the randomized data reflects the causal effect of LLM use on exam scores\nIn an OLS setting we refer to the selection bias issue as omitted variable bias (OVB)"
  },
  {
    "objectID": "lectures/lecture_3.html#ols-dillma-2",
    "href": "lectures/lecture_3.html#ols-dillma-2",
    "title": "Regressions and Identification",
    "section": "OLS DiLLMa",
    "text": "OLS DiLLMa\nThe Limits of ‚ÄúControlling For‚Äù\n\n\n\n\n\n\nImportant caveat\n\n\nIn DiLLMa, we could observe ability and control for it. In real research, we usually cannot observe all confounders.\n\n\n\nThe problem with observational data:\n\n\n\n\nWhat we did in DiLLMa\nWhat happens in reality\n\n\n\n\nObserved ability\nAbility is unobserved\n\n\nControlled for it in OLS\nCan‚Äôt control for what we don‚Äôt see\n\n\nGot the ‚Äútrue‚Äù effect\nEstimate remains biased\n\n\n\n\nThe solution?\n\nExperiments (when possible)\nQuasi-experimental methods (when experiments aren‚Äôt possible) ‚Üí Lecture 4"
  },
  {
    "objectID": "lectures/lecture_3.html#conclusion-1",
    "href": "lectures/lecture_3.html#conclusion-1",
    "title": "Regressions and Identification",
    "section": "Conclusion",
    "text": "Conclusion\nKey takeaway"
  },
  {
    "objectID": "lectures/lecture_3.html#conclusion-2",
    "href": "lectures/lecture_3.html#conclusion-2",
    "title": "Regressions and Identification",
    "section": "Conclusion",
    "text": "Conclusion\nWhat we learned today\n\n\nIdentification\n\nIdentification = isolating causal variation\nEndogeneity = X correlated with error term\nTwo main sources: selection bias & OVB\nCan flip the sign of estimates!\n\n\nTools\n\nExperiments: Gold standard, but often infeasible\nOLS with controls: Works if you observe all confounders\nNext lecture: What if you can‚Äôt experiment AND can‚Äôt observe all confounders?"
  },
  {
    "objectID": "lectures/lecture_3.html#conclusion-3",
    "href": "lectures/lecture_3.html#conclusion-3",
    "title": "Regressions and Identification",
    "section": "Conclusion",
    "text": "Conclusion\nLooking Ahead\nComing up: Lecture 4 - Panel Data Methods\nWhen we can‚Äôt run experiments AND controlling for observables isn‚Äôt enough, we need quasi-experimental methods:\n\nDifference-in-Differences (DiD)\nExploits variation across groups AND time\nCan identify causal effects without experiments\n\nWe‚Äôll continue the DiLLMa story with panel data!"
  },
  {
    "objectID": "lectures/lecture_3.html#references",
    "href": "lectures/lecture_3.html#references",
    "title": "Regressions and Identification",
    "section": "References",
    "text": "References\n\n\nB√©k√©s, G√°bor, and G√°bor K√©zdi. 2021. Data Analysis for Business, Economics, and Policy. Cambridge University Press.\n\n\nHuntington-Klein, Nick. 2022. The Effect: An Introduction to Research Design and Causality. 2nd ed. Chapman; Hall/CRC.\n\n\nVerbeek, Marno. 2021. Panel Methods for Finance: A Guide to Panel Data Econometrics for Financial Applications. De Gruyter."
  },
  {
    "objectID": "lectures/lecture_3.html#libby-boxes",
    "href": "lectures/lecture_3.html#libby-boxes",
    "title": "Regressions and Identification",
    "section": "Libby Boxes",
    "text": "Libby Boxes\nDiLLMa\n Back"
  },
  {
    "objectID": "lectures/lecture_3.html#the-gold-standard-experiments-7",
    "href": "lectures/lecture_3.html#the-gold-standard-experiments-7",
    "title": "Regressions and Identification",
    "section": "The gold standard: Experiments",
    "text": "The gold standard: Experiments\nDiLLMa experiment\nCovariate balance check - no random assignment!\n\n\n\n\n\n\nVariable\nLLM\nNo LLM\nDifference\nt-stat.\np-value\n\n\n\n\nExam score\n7.04\n6.55\n0.50\n-5.99\n0.00\n\n\nAttendance rate\n74.15\n75.43\n-1.28\n1.42\n0.15\n\n\nFemale\n0.49\n0.50\n-0.01\n0.39\n0.70\n\n\nAge\n21.37\n21.34\n0.03\n-0.18\n0.86\n\n\nStudy hours\n20.09\n20.34\n-0.25\n0.35\n0.73\n\n\nAbility\n0.56\n-0.50\n1.07\n-20.11\n0.00"
  },
  {
    "objectID": "lectures/lecture_3.html#theory-hypotheses-and-operationalisation",
    "href": "lectures/lecture_3.html#theory-hypotheses-and-operationalisation",
    "title": "Regressions and Identification",
    "section": "Theory, hypotheses, and operationalisation",
    "text": "Theory, hypotheses, and operationalisation\nWhat is a hypothesis?\n\nA hypothesis is a proposed explanation for a phenomenon or a prediction of a possible causal correlation\nIt is a tentative answer to a research question that guides the direction of study and investigation\nIts formulation is guided by existing (economic) theory\nA well-constructed hypothesis is testable, meaning it can be supported or rejected through experimentation"
  },
  {
    "objectID": "lectures/lecture_3.html#theory-hypotheses-and-operationalisation-1",
    "href": "lectures/lecture_3.html#theory-hypotheses-and-operationalisation-1",
    "title": "Regressions and Identification",
    "section": "Theory, hypotheses, and operationalisation",
    "text": "Theory, hypotheses, and operationalisation\nHow do we test a hypothesis?\n\nStepst-testVisual\n\n\n\nWe need a baseline to test against: The null hypothesis (\\(H_0\\))\nWhy null? It states that there is no effect or no difference, which serves as a baseline assumption\n\n\\(H_0\\) is what you test your \\(H_1\\) against, e.g.¬†\\(H_0 = 0\\)\n\\(H_1\\) is the/your alternative hypothesis - what you might believe to be true\n\nA statistical test rejects \\(H_0\\) if there is enough evidence against it\n\nIf we reject \\(H_0\\), we accept \\(H_1\\)\n\n\n\n\nThe t-test measures how far the sample mean is away from \\(H_0\\)\nHypothesis:\n\nOne-sided (\\(H_0 \\leq 0\\), \\(H_1&gt;0\\)): \\(t = \\frac{X-0}{SE(X)}\\)\nTwo-sided (\\(H_0 = 0\\), \\(H_1 \\neq 0\\)): \\(t = \\frac{X_{treated}-X_{control}}{SE(X_{treated}-X_{control})}\\)"
  },
  {
    "objectID": "lectures/lecture_5.html#overview",
    "href": "lectures/lecture_5.html#overview",
    "title": "Event Studies (CAR) and Fama‚ÄìMacBeth",
    "section": "Overview",
    "text": "Overview"
  },
  {
    "objectID": "lectures/lecture_5.html#overview-1",
    "href": "lectures/lecture_5.html#overview-1",
    "title": "Event Studies (CAR) and Fama‚ÄìMacBeth",
    "section": "Overview",
    "text": "Overview\nRecap of previous lecture"
  },
  {
    "objectID": "lectures/lecture_5.html#overview-2",
    "href": "lectures/lecture_5.html#overview-2",
    "title": "Event Studies (CAR) and Fama‚ÄìMacBeth",
    "section": "Overview",
    "text": "Overview\nToday‚Äôs learning objectives"
  },
  {
    "objectID": "lectures/lecture_5.html#overview-3",
    "href": "lectures/lecture_5.html#overview-3",
    "title": "Event Studies (CAR) and Fama‚ÄìMacBeth",
    "section": "Overview",
    "text": "Overview\nKey concepts"
  },
  {
    "objectID": "lectures/lecture_5.html#references",
    "href": "lectures/lecture_5.html#references",
    "title": "Event Studies (CAR) and Fama‚ÄìMacBeth",
    "section": "References",
    "text": "References"
  }
]